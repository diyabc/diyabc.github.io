<h1 id="user-manual-for-diyabc-random-forest-v1.0">USER MANUAL for DIYABC Random Forest v1.0</h1>
<ul>
<li><h1 id="of-july-2020--">3 of July 2020 -</h1></li>
</ul>
<p>François-David Collin <sup>1,*</sup>, Ghislain Durif <sup>1,*</sup>, Louis Raynal <sup>1</sup>, Eric Lombaert <sup>2</sup>, Mathieu Gautier <sup>3</sup>, Renaud Vitalis <sup>3</sup>, Jean-Michel Marin <sup>1,&amp;</sup>, Arnaud Estoup <sup>3,&amp;</sup></p>
<p><sup>1</sup> IMAG, Univ Montpellier, CNRS, UMR 5149, Montpellier, France</p>
<p><sup>2</sup> ISA, INRAE, CNRS, Univ Côte d’Azur, Sophia Antipolis, France</p>
<p><sup>3</sup> CBGP, Univ Montpellier, CIRAD, INRAE, Institut Agro, IRD, Montpellier, France</p>
<p><sup>*</sup> Equal contribution (F-D.C.: computation part of the program; S.D.: interface part of the program)</p>
<p><sup>&amp;</sup> These authors are joint senior authors on this work</p>
<p>Corresponding authors:</p>
<p>Arnaud Estoup. E-mail: <a href="mailto:arnaud.estoup@.inrae.fr">arnaud.estoup@.inrae.fr</a></p>
<p>Francois-David.Collin: Francois-David.Collin@umontpellier.fr</p>
<p>Ghislain Durif: ghislain.durif@umontpellier.fr</p>
<h1 id="contents">CONTENTS</h1>
<p><strong>Warning: Activate the option “Navigation panel” after opening this file<em>.</em> This navigation panel, visible on the left size of the document once activated, will allow you reaching directly through simple click actions the different sections and sub-sections described below.</strong></p>
<p>PLAN ICI (ne pas donner les numeros pages car pourra evoluer)</p>
<p>1. (BRIEF) INTRODUCTION</p>
<p>1.1 General context</p>
<p>1.2 How to cite the program DIYABC Random Forest v1.0</p>
<p>1.3 Web site</p>
<p>1.4. System requirements, installing and launching the program</p>
<p>1.5 Acknowledgements</p>
<p>2. FORMALIZATION OF SCENARIOS AND GENERATION OF THE TRAINING SET</p>
<p>2.1 Basic notions</p>
<p>2.2 Main features of algorithms for data simulation</p>
<p>2.3 Historical model parameterization</p>
<p>2.3.1 Key notes</p>
<p>2.3.2 Examples</p>
<p>2.4 Mutation model parameterization (microsatellite and DNA sequence loci)</p>
<p>2.4.1 Microsatellite loci</p>
<p>2.4.2 DNA sequence loci</p>
<p>2.4.3 SNPs do not require mutation model parameterization – notion of MAF and MRC</p>
<p>2.5 Prior distributions</p>
<p>2.6 Summary statistics as components of the feature vector</p>
<p>2.6.1 For microsatellite loci</p>
<p>2.6.2 For DNA sequence loci</p>
<p>2.6.3 For SNP loci</p>
<p>2.7 Generating the training set</p>
<p>3. RANDOM FOREST ANALYSIS</p>
<p>3.1 Addition of linear combinations of summary statistics to the vector feature</p>
<p>3.2 Prediction using Random Forest: scenario choice</p>
<p>3.3 Prediction using Random Forest: parameter estimation</p>
<p>3.4 Assessing the quality of predictions</p>
<p>3.4.1 Indices for scenario choice</p>
<p>3.4.2 Indices for parameter estimation</p>
<p>4. PRACTICAL CONSIDERATIONS FOR ABC-RF TREATMENTS</p>
<p>4.1 Are my scenarios and/or associated priors compatible with the observed dataset?</p>
<p>4.2 Did I simulate enough datasets for my training set?</p>
<p>4.3 Did my forest grow enough trees?</p>
<p>5. RUNNING (EXAMPLE) DATASET TREATMENTS USING THE GRAPHIC USER INTERFACE (GUI)</p>
<p>5.1 Launching the GUI</p>
<p>5.2 What is a DIYABC Random Forest project?</p>
<p>5.3 Main options of the home screen</p>
<p>5.4 How to generate an IndSeq SNP training set</p>
<p>5.4.1 Step 1: defining a new IndSeq SNP project</p>
<p>5.4.2 Step 2: choosing the data file</p>
<p>5.4.3 Step 3: Inform the Historical model</p>
<p>5.4.4 Step 4: Inform chromosome type and number of loci</p>
<p>5.4.5 Step 5: Summary statistics</p>
<p>5.4.6 Step 6: Simulate the training set</p>
<p>5.4.7 Step 7 (optional but recommended): Prior-scenario checking PRE-ANALYSIS</p>
<p>5.5 How to generate a PoolSeq SNP training set</p>
<p>5.6 How to generate a microsatellite (and/or sequence) training set</p>
<p>5.6.1 Step 4: Inform the genetic model</p>
<p>5.6.2 Step 5: Summary statistics</p>
<p>6. PERFORMING RANDOM FOREST ANALYSES</p>
<p>6.1 Files needed</p>
<p>6.2. Scenario choice analysis</p>
<p>6.3. Parameter estimation analysis</p>
<p>7. KEY FILES</p>
<p>7.1 Data files</p>
<p>7.1.1 IndSeq SNP data</p>
<p>7.1.2 PoolSeq SNP data</p>
<p>7.1.3 Microsatellite and DNA sequence data</p>
<p>7.2 Training set file(s)</p>
<p>7.3 Output files produced by a Random Forest analysis</p>
<p>7.4 Other files</p>
<p>8. USING DIYABC RANDOM FOREST ON A COMPUTER CLUSTER</p>
<p>9. REFERENCES CITED</p>
<h1 id="brief-introduction">1. (BRIEF) INTRODUCTION</h1>
<h2 id="general-context">1.1 General context </h2>
<blockquote>
<p>Simulation-based methods such as Approximate Bayesian Computation (ABC) are well adapted to the analysis of complex models of populations and species genetic history (Beaumont 2010). In this context, supervised machine learning (SML) methods provide attractive statistical solutions to conduct efficient inferences about both scenario choice and parameter estimation (Schrider &amp; Kern 2018). The Random Forest methodology (RF) is a powerful ensemble of SML algorithms used for both classification and/or regression problems (Breiman 2001). RF allows conducting inferences at a lower computational cost than ABC, without preliminary selection of the relevant components of the ABC summary statistics, and bypassing the derivation of ABC tolerance levels (Pudlo et al. 2018; Raynal et al. 2019). We have implemented a set of RF algorithms to process inferences using simulated datasets generated from an extended version of the population genetic simulator implemented in DIYABC v2.1.0 (Cornuet et al. 2014). The resulting computer package, named DIYABC Random Forest v1.0, integrates two functionalities into a user-friendly interface: the simulation under custom evolutionary scenarios of different types of molecular data (microsatellites, DNA sequences or SNPs – including traditional <strong>IndSeq</strong> and more recent <strong>PoolSeq</strong> SNP data) and RF treatments including statistical tools to evaluate the power and accuracy of inferences (Collin et al. 2020). Because of the properties inherent of the implemented RF methods and the large feature vector (including various summary statistics and their linear combinations) available for SNP data, DIYABC Random Forest v1.0 can efficiently contribute to the analysis of large-size SNP (and other molecular markers) datasets to make inferences about complex population genetic histories.</p>
</blockquote>
<h2 id="how-to-cite-the-program-diyabc-random-forest-v1.0">1.2 How to cite the program DIYABC Random Forest v1.0</h2>
<blockquote>
<p>Collin F-D, Raynal L, Durif G, Gautier M, Vitalis R, Lombaert E., Marin J-M, Estoup A (2020) DIYABC Random Forest v1.0: extending approximate Bayesian computation with supervised machine learning to infer demographic history from genetic polymorphisms. Submitted to <em>Molecular Ecology Resources</em>. ### bioRxiv ####</p>
</blockquote>
<h2 id="web-site">1.3 Web site</h2>
<p><a href="https://diyabc.github.io">https://diyabc.github.io</a>.</p>
<p>You can get from this github site the executable files for different operating systems, the latest version of this manual document, as well as examples of DIYABC Random Forest analyses for different type of markers.</p>
<h2 id="system-requirements-installing-and-launching-the-program">1.4. System requirements, installing and launching the program</h2>
<ul>
<li><p>The package DIYABC Random Forest v1.0 is composed of three parts: the dataset simulator, the Random Forest inference engine and the graphical user interface. The whole is packaged as a standalone and user-friendly application available at <a href="https://diyabc.github.io">https://diyabc.github.io</a> The different developer and user manuals for each component of the package are available on the same site. DIYABC Random Forest v1.0 is a multithreaded program which runs on three operating systems: GNU/Linux, Microsoft Windows and MacOS. The program can be used through a modern and user-friendly graphical interface designed as an R shiny application (Chang et al. 2019). For a fluid and simplified user experience, this interface is available through a standalone application, which does not depend on R and hence can be used independently. The application is also implemented in a R package providing a standard shiny web application (with the same graphical interface) that can be run locally as any shiny application, or hosted as a web service to provide a DIYABC Random Forest v1.0 server for multiple users.</p></li>
<li><p><u>To launch the program</u>: install doing that…click to launch…etc</p></li>
<li><p>Minimum 4GB of RAM; 6GB of RAM recommended</p></li>
<li><p>From 1 to 10 GB free disk space for each DIYABC Random Forest v1.0 project depending on the project configuration and the number of simulated datasets recorded in the training set file (reftableRF.bin file).</p></li>
</ul>
<h2 id="acknowledgements">1.5 Acknowledgements</h2>
<p>We thank Pierre Pudlo for useful discussions and Jean-Marie Cornuet for computer code expertise at the onset of the ABC Random Forest project. We also thank several “beta-users”, especially XXXNAMEXXX, who tested the software DIYABC Random Forest v1.0 with their data. This work was supported by funds from the French Agence National pour la Recherche (ANR projects SWING and GANDHI), the INRAE scientific division SPE (AAP-SPE 2016), and the LabEx NUMEV (NUMEV, ANR10-LABX-20).</p>
<h1 id="formalization-of-scenarios-and-generation-of-the-training-set">2. FORMALIZATION OF SCENARIOS AND GENERATION OF THE TRAINING SET</h1>
<h2 id="basic-notions">2.1 Basic notions</h2>
<p>Before processing Random Forest analyses, one need to generate a <em>training set</em> which corresponds to the so called <em>reference table</em> in a standard ABC framework (Cornuet et al. 2014 and see the associated program DIYABC v2.1.0). The datasets composing the training set can be simulated under different models (hereafter referred to as scenarios) and sample (i.e. nb of markers and sampled individuals) configurations, using parameter values drawn from prior distributions. Each resulting dataset is summarized using a set of descriptive statistics. Scenarios and prior distributions are formalized and summary statistics are computed using the “Training set simulation” module of the main pipeline of DIYABC Random Forest v1.0, which essentially corresponds to an extended version of the population genetics simulator implemented in DIYABC v2.1.0 (Cornuet et al. 2014). As in the latter program, DIYABC Random Forest v1.0 allows considering complex population histories including any combination of population divergence events, symmetrical or asymmetrical admixture events (but not any continuous gene flow between populations) and changes in past population size, with population samples potentially collected at different times. Statistical analysis based on Random Forest algorithms of an observed dataset using a given training set are computed using the “Random Forest Analysis” module of the main pipeline of the program.</p>
<h2 id="main-features-of-algorithms-for-data-simulation">2.2 Main features of algorithms for data simulation</h2>
<p>The ABC part of DIYABC Random Forest is a simulation-based method. Data simulation is based on the Wright-Fisher model. It consists in generating the genealogy of all sampled genes until their most recent common ancestor using (backward in time) coalescence theory. This begins by randomly drawing a complete set of parameters from their own prior distributions and that satisfy all imposed conditions. Then, once events have been ordered by increasing times, a sequence of <em>actions</em> is constructed. If there is more than one locus, the same sequence of actions is used for all successive loci.</p>
<p>Possible <em>actions</em> fall into four categories:</p>
<p>- <strong>adding a sample to a population</strong> = Add as many gene lineages to the population as there are genes in the sample.</p>
<p>- <strong>merge two populations</strong> = Move the lineages of the second population into the first population.</p>
<p>- <strong>split between two populations</strong> = Distribute the lineages of the admixed population among the two parental populations according to the admixture rate.</p>
<p>- <strong>coalesce and mutate lineages within a population</strong> = There are two possibilities here, depending on whether the population is <em>terminal</em> or not. We call <em>terminal</em> the population including the most recent common ancestor of the whole genealogy. In a terminal population, coalescences and mutations stop when the MRCA is reached whereas in a non-terminal population, coalescence and mutations stop when the upper (most ancient) limit is reached. In the latter case, coalescences can stop before the upper limit is reached because there remains a single lineage, but this single remaining lineage can still mutate.</p>
<p>Two different coalescence algorithms are implemented: a generation by generation simulation or a continuous time simulation. The choice, automatically performed by the program, is based on an empirical criterion which ensures that the continuous time algorithm is chosen whenever it is faster than generation by generation while keeping the relative error on the coalescence rate below 5% (see Cornuet et al. 2008 for a description of this criterion). In any case, a coalescent tree is generated over all sampled genes.</p>
<p>Then the mutational simulation process diverges depending on the type of markers: for microsatellite or DNA sequence loci, mutations are distributed over the branches according to a Poisson process whereas for SNP loci, one mutation is applied to a single branch of the coalescent tree, this branch being drawn at random with probability proportional to its length. Eventually, starting from an ancestral allelic state (established as explained below), all allelic states of the genealogy are deduced forward in time according to the mutation process. For microsatellite loci, the ancestral allelic state is taken at random in the stationary distribution of the mutation model (not considering potential single nucleotide indel mutations). For DNA sequence loci, the procedure is slightly more complicated. First, the total number of mutations over the entire tree is evaluated. Then according to the proportion of constant sites and the gamma distribution of individual site mutation rates, the number and position of mutated sites are generated. Finally, these mutated sites are given ‘A’, ‘T’, ‘G’ or ‘C’ states according to the selected mutation model. For SNP loci, the ancestral allelic state is arbitrarily set to 0 and it becomes equal to 1 after mutation.</p>
<div class="Definition-Term">
<p>Each category of loci has its own coalescence rate deduced from male and female effective population sizes. In order to combine different categories (e.g. autosomal and mitochondrial), we have to take into account the relationships among the corresponding effective population sizes. This can be achieved by linking the different effective population sizes to the effective number of males ( <span class="math inline"><strong>N</strong><sub><strong>M</strong></sub></span> ) and females (<span class="math inline"><strong>N</strong><sub><strong>F</strong></sub></span>) through the sum <span class="math inline"><strong>N</strong><sub><strong>T</strong></sub><strong>=</strong><strong>N</strong><sub><strong>F</strong></sub><strong>+</strong><strong>N</strong><sub><strong>M</strong></sub></span> and the ratio <span class="math inline"><strong>r</strong><strong>=</strong><strong>N</strong><sub><strong>M</strong></sub><strong>/</strong><strong>(</strong><strong>N</strong><sub><strong>F</strong></sub><strong>+</strong><strong>N</strong><sub><strong>M</strong></sub><strong>)</strong></span>. We use the following formulae for the probability of coalescence (<em>p</em>) of two lineages within this population:</p>
</div>
<div class="Definition-Term">
<p>Autosomal diploid loci:</p>
</div>
<p><span class="math display">$$p = \frac{1}{8r(1 - r)N_{T}}$$</span></p>
<div class="Definition-Term">
<p>Autosomal haploid loci:</p>
</div>
<p><span class="math display">$$p = \frac{1}{4r(1 - r)N_{T}}$$</span></p>
<div class="Definition-Term">
<p>X-linked loci / haplo-diploid loci:</p>
</div>
<p><span class="math display">$$p = \frac{1 + r}{9r(1 - r)N_{T}}$$</span></p>
<div class="Definition-Term">
<p>Y-linked loci:</p>
</div>
<p><span class="math display">$$p = \frac{1}{rN_{T}}$$</span></p>
<div class="Definition-Term">
<p>Mitochondrial loci:</p>
</div>
<p><span class="math display">$$p = \frac{1}{(1 - r)N_{T}}$$</span></p>
<div class="Definition">
<p>Users have to provide a (total) effective size <span class="math inline"><em>N</em><sub><em>T</em></sub></span> (on which inferences will be made) and a sex-ratio <span class="math inline"><em>r</em></span>. If no sex ratio is provided, the default value of <span class="math inline"><em>r</em></span> is taken as 0.5.</p>
</div>
<h2 id="historical-model-parameterization">2.3 Historical model parameterization</h2>
<p>The evolutionary scenario, which is characterized by the historical model, can be described in a dedicated panel of the interface of the program as a succession in time of "events" and "inter event periods". In the current version of the program, we consider 4 categories of events: population divergence, discrete change of effective population size, admixture and sampling (the last one allow considering samples taken at different times). Between two successive events affecting a population, we assume that populations evolve independently (e.g. without migration) and with a fixed effective size. The usual parameters of the historical model are the times of occurrence of the various events (counted in number of generations), the effective sizes of populations and the admixture rates. <strong>When writing the scenario, events have to be coded sequentially backward in time</strong> (see section 2.3.2 for examples). Although this choice may not be natural at first sight, it is coherent with coalescence theory on which are based all data simulations in the program. For that reason, the keywords for a divergence or an admixture event are <code>merge</code> and <code>split</code>, respectively. Two keywords <code>varNe</code> and <code>sample</code> correspond to a discrete change in effective population size and a gene sampling within a given population, respectively. A scenario takes the form of a succession of lines (one line per event), each line starting with the time of the event, then the nature of the event, and ending with several other data depending on the nature of the event. Following is the syntax used for each category of event:</p>
<dl>
<dt>Population sample</dt>
<dd><p><span class="math inline">⟨<em>t</em><em>i</em><em>m</em><em>e</em>⟩</span> <code>sample</code> <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>⟩</span></p>
<p>Where <span class="math inline">⟨<em>t</em><em>i</em><em>m</em><em>e</em>⟩</span> is the time (always counted in number of generations) at which the sample was collected and <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>⟩</span> is the population number from which is taken the sample. It is worth stressing here that <strong>samples are considered in the same order as they appear in the data file</strong>. The number of lines will thus be exactly equal to the number of samples in the datafile.</p>
<p><strong>Population size variation</strong></p>
<p><span class="math inline">⟨<em>t</em><em>i</em><em>m</em><em>e</em>⟩</span> <code>varNe</code> <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>⟩</span> <span class="math inline">⟨<em>N</em><em>e</em>⟩</span><br />
From time <span class="math inline">⟨<em>t</em><em>i</em><em>m</em><em>e</em>⟩</span>, looking backward in time, population <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>⟩</span> will have an effective size <span class="math inline">⟨<em>N</em><em>e</em>⟩</span>.</p>
</dd>
<dt>Population divergence</dt>
<dd><p><span class="math inline">⟨<em>t</em><em>i</em><em>m</em><em>e</em>⟩</span> <code>merge</code> <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>1⟩</span> <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>0⟩</span><br />
At time <span class="math inline">⟨<em>t</em><em>i</em><em>m</em><em>e</em>⟩</span>, looking backward in time, population <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>0⟩</span> "merges" with population <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>1⟩</span>. Hereafter, only <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>1⟩</span> "remains".</p>
</dd>
<dt>Population admixture</dt>
<dd><p><span class="math inline">⟨<em>t</em><em>i</em><em>m</em><em>e</em>⟩</span> <code>split</code> <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>0⟩</span> <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>1⟩</span> <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>2⟩</span> <span class="math inline">⟨<em>r</em><em>a</em><em>t</em><em>e</em>⟩</span><br />
At time <span class="math inline">⟨<em>t</em><em>i</em><em>m</em><em>e</em>⟩</span>, looking backward in time, population <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>0⟩</span> "splits" between populations <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>1⟩</span> and <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>2⟩</span>. A gene lineage from population <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>0⟩</span> joins population <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>1⟩</span> (respectively <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>2⟩</span>) with probability <span class="math inline">⟨<em>r</em><em>a</em><em>t</em><em>e</em>⟩</span> (respectively 1-<span class="math inline">⟨<em>r</em><em>a</em><em>t</em><em>e</em>⟩</span>). Hereafter, only <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>1⟩</span> and <span class="math inline">⟨<em>p</em><em>o</em><em>p</em>2⟩</span> "remain".</p>
</dd>
</dl>
<p>Note that one needs to write a first line giving the <strong>effective sizes of the sampled populations before the first event described</strong>, looking backward in time. Expressions between arrows, other than population numbers, can be either a numeric value (e.g. 25) or a character string (e.g. <code>t0</code>). In the latter case, it is considered as a parameter of the model. The program offers the possibility to add or remove scenarios, by just clicking on the corresponding buttons. The usual shortcuts (e.g. CTRL+C, CTRL+V and CTRL+X) can be used to edit the different scenarios. Some or all parameters can be in common among scenarios.</p>
<h3 id="key-notes">2.3.1 Key notes</h3>
<ol type="1">
<li><p>There are two ways of giving a fixed value to effective population sizes, times and admixture rates. Either the fixed value appears as a numeric value in the scenario windows or it is given as a string value like any parameter. In the latter case, one gives this parameter a fixed value by choosing a Uniform distribution and setting the minimum and maximum to that value in the prior setting of the corresponding interface panel.</p></li>
<li><p>All expressions must be separated by at least one space.</p></li>
<li><p>All expressions relative to parameters can include sums or differences. For instance, it is possible to write:<br />
<code>t0 merge 2 3</code><br />
<code>t0+t1 merge 1 2</code><br />
This means that <code>t1</code> is the time elapsed between the two merge events. Note that one cannot mix a parameter and a numeric value (e.g. <code>t1+150</code> will result in an error). This can be done by writing <code>t1+t2</code> and fixing <code>t2</code> by choosing a uniform distribution with lower and upper bounds both equal to 150 in the interface.</p></li>
<li><p><strong>Time is always given in generations</strong>. Since we look backward, time increases towards past.</p></li>
<li><p>Negative times are allowed (e.g. the example given in section 2.3.2), but not recommended.</p></li>
<li><p>Population numbers must be consecutive natural integers starting at 1. The number of population can exceed the number of samples and vice versa: in other words, <em>unsampled populations</em> can be considered in the scenario on one hand, and the same population can be sampled more than once on the other hand.</p></li>
<li><p><strong>Multi-furcating population trees</strong> can be considered, by writing <strong>several divergence events occurring at the same time.</strong> However, one has to be careful to the order of the <code>merge</code> events. For instance, the following piece of scenario will fail:<br />
<code>100 merge 1 2</code><br />
<code>100 merge 2 3</code><br />
This is because, after the first line, population 2, which has merged with population 1, does not "exist" anymore (the remaining population is population 1). So, it cannot receive lineages of population 3 as it should as a result of the second line. The correct ways are either to put line 2 before line 1, or to change line 2 to:<br />
<code>100 merge 1 3</code>.</p></li>
<li><p>Since times of events can be parameters, the order of events can change according to the values taken by the time parameters. In any case, before simulating a dataset, the program sorts out events by increasing times. Note that sorting out events by increasing times can only be done when all time values are known, i.e. when simulating datasets. When checking scenarios in the interface, all time values are not yet defined, so that when visualizing a scenario, events are represented in the same order as they appear in the window used to define the scenario. If two or more events occur at the same time, the order is that of the scenario as it is written by the user.</p></li>
<li><p>Most scenarios begin with sampling events. We then need to know the effective size of the populations to perform the simulation of coalescences until the next event concerning each population. We decided to provide the effective size (first line) and the sampling description (following lines) on distinct lines.</p></li>
</ol>
<p><strong>2.3.2 Examples</strong></p>
<p>Below are some usual scenarios with increasing complexity. Each scenario is coded (as in the corresponding interface panel of the program) on the left side and a graphic representation (given by DIYABC Random Forest) is printed on the right side</p>
<ol type="1">
<li><p>One population from which several samples have been taken at various generations: 0, 3 and 10. Generation 0 could correspond for instance to the most recent sampling date. The only unknown historical-demographical parameter of the scenario is the (constant) effective population size which is defined in the first line at sampling time.</p></li>
</ol>
<table>
<tbody>
<tr class="odd">
<td><ul>
<li><img src="media/image1.png" style="width:1.08333in;height:0.81667in" alt="image" /></li>
</ul></td>
<td><ul>
<li><img src="media/image2.png" style="width:2.63333in;height:2.15833in" alt="image" /></li>
</ul></td>
</tr>
</tbody>
</table>
<ol start="2" type="1">
<li><p>Two populations of size <code>N1</code> and <code>N2</code> (defined in the first line at sampling time) have diverged <code>t</code> generations in the past from an ancestral population of size <code>N1+N2</code>.</p></li>
</ol>
<table>
<tbody>
<tr class="odd">
<td><ul>
<li><img src="media/image3.png" style="width:1.45833in;height:0.85833in" alt="image" /></li>
</ul></td>
<td><ul>
<li><img src="media/image4.png" style="width:2.69167in;height:2.13333in" alt="image" /></li>
</ul></td>
</tr>
</tbody>
</table>
<ol start="3" type="1">
<li><p>Two parental populations (1 and 2) with constant effective population sizes <code>N1</code> and <code>N2</code> have diverged at time <code>td</code> from an ancestral population of size <code>NA</code>. At time <code>ta</code>, there has been an <u>admixture event</u> between the two populations giving birth to an admixed population (3) with effective size <code>N3</code> and with an admixture rate <code>ra</code> relative to population 1.</p></li>
</ol>
<table>
<tbody>
<tr class="odd">
<td><ul>
<li><img src="media/image5.png" style="width:1.51667in;height:1.225in" alt="image" /></li>
</ul></td>
<td><ul>
<li><img src="media/image6.png" style="width:3.36111in;height:2.60185in" alt="image" /></li>
</ul></td>
</tr>
</tbody>
</table>
<ol start="4" type="1">
<li><p>The next scenario includes <u>four population samples and two admixture events</u>. All populations have identical effective sizes (<code>Ne</code>).</p></li>
</ol>
<table>
<tbody>
<tr class="odd">
<td><ul>
<li><img src="media/image7.png" style="width:1.51667in;height:1.225in" alt="image" /></li>
</ul></td>
<td><ul>
<li><img src="media/image8.png" style="width:3.36111in;height:2.73148in" alt="image" /></li>
</ul></td>
</tr>
</tbody>
</table>
<ul>
<li><p>Note that although there are only four samples, the scenario includes a fifth <u>unsampled population</u>. This unsampled population which diverged from population 1 at time <code>t3</code> was a parent in the admixture event occurring at time <code>t2</code>. Note also that the first line must include the effective sizes of the <em>five</em> populations.</p></li>
</ul>
<ol start="5" type="1">
<li><p>The following three scenarios correspond to a classic invasion history from an ancestral population (population 1<u>). In scenario 1, population 3 is derived from population 2, itself derived from population 1. In scenario 2, population 2 derived from population 3, itself derived from population 1. In scenario 3, both populations 2 and 3 derived independently from population 1.</u> Note that when a new population is created from its ancestral population, there is an initial size reduction (noted here <code>N2b</code> for population 2 and <code>N3b</code> for population 3) for a given number of generation (here db for both populations) mimicking a demographic bottleneck since the invasive population generally starts with a few immigrants. For instance, a low number of Nxb individuals for db generations could corresponds to Nxb values ranging between 5 to 100 individuals and db values ranging from 1 to 10 generations (e.g. Fraimout et al. 2017). If db = 0 then no bottleneck occur which can be also a coding choice.</p></li>
</ol>
<p>Scenario 1</p>
<table>
<tbody>
<tr class="odd">
<td><img src="media/image9.png" style="width:1.575in;height:1.68333in" alt="image" /></td>
<td><img src="media/image10.png" style="width:4.37037in;height:4.09259in" alt="image" /></td>
</tr>
</tbody>
</table>
<p>Scenario 2</p>
<table>
<tbody>
<tr class="odd">
<td><img src="media/image11.png" style="width:1.63333in;height:1.54167in" alt="image" /></td>
<td><img src="media/image12.png" style="width:4.31481in;height:4.05556in" alt="image" /></td>
</tr>
</tbody>
</table>
<p>Scenario 3</p>
<table>
<tbody>
<tr class="odd">
<td><img src="media/image13.png" style="width:1.525in;height:1.31667in" alt="image" /></td>
<td><img src="media/image14.png" style="width:4.24074in;height:3.40741in" alt="image" /></td>
</tr>
</tbody>
</table>
<h2 id="mutation-model-parameterization-microsatellite-and-dna-sequence-loci">2.4 Mutation model parameterization (microsatellite and DNA sequence loci)</h2>
<p>The program can analyze microsatellite data and DNA sequence data altogether as well as separately. SNP loci can be also analyzed separately from microsatellite data and DNA sequence data. It is worth stressing that all loci in an analysis must be <u>genetically independent</u>. Second, for DNA sequence loci, intralocus recombination is not considered. Loci are grouped by the user according to its needs. For microsatellite and DNA sequence, a different mutation model can be defined for each group. For instance, one group can include all microsatellites with motifs that are 2 bp long and another group those with a 4 bp long motif. Also, with DNA sequence loci, nuclear loci can be grouped together and a mitochondrial locus form a separate group. <u>SNPs do not require mutation model parameterization (see below for details)</u>.</p>
<p>We now describe the parameterization of microsatellite and DNA sequence markers.</p>
<h3 id="microsatellite-loci">2.4.1 Microsatellite loci</h3>
<p>Although a variety of mutation models have been proposed for microsatellite loci, it is usually sufficient to consider only the simplest models (e.g. Estoup et al. 2002). This has the non-negligible advantage of reducing the number of parameters. This is why we chose the Generalized Stepwise Mutation model (GSM). Under this model, a mutation increases or decreases the length of the microsatellite by a number of repeated motifs following a geometric distribution. This model necessitates only two parameters: the mutation rate (<code>µ</code>) and the parameter of the geometric distribution (<code>P</code>). The same mutation model is imposed to all loci of a given group. However, each locus has its own parameters (µ<sub>i</sub> and P<sub>i</sub><code>) </code>and, following a hierarchical scheme, each locus parameter is drawn from a gamma distribution with mean equal to the mean parameter value.</p>
<p>Note also that:</p>
<ol type="1">
<li><p>Individual loci parameters (µi and Pi) are considered as nuisance parameters and hence are never recorded. Only mean parameters are recorded.</p></li>
<li><p>The variance or shape parameter of the gamma distributions are set by the user and are NOT considered as parameters.</p></li>
<li><p>The SMM or Stepwise Mutation Model is a special case of the GSM in which the number of repeats involved in a mutation is always one. Such a model can be easily achieved by setting the maximum value of mean P (<span class="math inline">$\overline{P}$</span>) to 0. In this case, all loci have their <span class="math inline"><em>P</em><sub><em>i</em></sub></span> set equal to 0 whatever the shape of the gamma distribution.</p></li>
<li><p>All loci can be given the same value of a parameter by setting the shape of the corresponding gamma distribution to 0 (this is NOT a limiting case of the gamma, but only a way of telling the program).</p></li>
</ol>
<p>To give more flexibility to the mutation model, the program offers the possibility to consider <u>mutations that insert or delete a single nucleotide</u> to the microsatellite sequence by using a mean parameter (named <span class="math inline"><em>μ</em><sub>(<em>S</em><em>N</em><em>I</em>)</sub></span>) with a prior to be defined and individual loci having either values identical to the mean parameter or drawn from a Gamma distribution.</p>
<h3 id="dna-sequence-loci">2.4.2 DNA sequence loci</h3>
<p>The program does not consider insertion-deletion mutations, mainly because there does not seem to be much consensus on this topic. Concerning substitutions, only the simplest models are considered. We chose the Jukes-Cantor (1969) one parameter model, the Kimura (1980) two parameter model, the Hasegawa-Kishino-Yano (1985) and the Tamura-Nei (1993) models. The last two models include the ratios of each nucleotide as parameters. In order to reduce the number of parameters, these ratios have been fixed to the values calculated from the observed dataset for each DNA sequence locus. Consequently, this leaves two and three parameters for the Hasegawa-Kishino-Yano (HKY) and Tamura-Nei (TN), respectively. Also, two adjustments are possible: one can fix the fraction of constant sites (those that cannot mutate) on the one hand and the shape of the Gamma distribution of mutations among sites on the other hand. As for microsatellites, all sequence loci of the same group are given the same mutation model with mean parameter(s) drawn from priors and each locus has its own parameter(s) drawn from a Gamma distribution (same hierarchical scheme). Notes 1, 2 and 4 of previous subsection (2.4.1) apply also for sequence loci.</p>
<h3 id="snps-do-not-require-mutation-model-parameterization-notion-of-maf-and-mrc">2.4.3 SNPs do not require mutation model parameterization – notion of MAF and MRC</h3>
<p>SNPs have two characteristics that allow to get rid of mutation models: they are (necessarily) polymorphic and they present only two allelic states (ancestral and derived). In order to be sure that all analyzed SNP loci have the two characteristics, <u>non polymorphic loci are discarded right from the beginning of analyses</u>. Note that a warning message will appear if the observed dataset include monomorphic loci, the latter being automatically removed from further analyses by the program. Consequently, one can assume that there occurred one and only one mutation in the coalescence tree of sampled genes. We will see below that this largely simplifies (and speeds up) SNP data simulation as one can use in this case the efficient “-s” algorithm of Hudson (2002) (Cornuet et al. 2014). Also, this advantageously reduces the dimension of the parameter space as mutation parameters are not needed in this case. There is however a potential drawback which is the absence of any calibration generally brought by priors on mutation parameters. <u>Consequently, time/effective size ratios rather than original time or effective size parameters will be informative</u>.</p>
<p>It is worth noting that, using the Hudson’s simulation algorithm for SNP markers leads to applying a default <u>MAF (minimum allele frequency)</u> criterion on the simulated dataset. As a matter of fact, each locus in both the observed and simulated datasets will be characterized by the presence of at least one copy of the SNP alleles over all genes sampled from all studied populations (i.e. pooling all genes genotyped at the locus). In DIYABC Random Forest v1.0, it is possible to impose a given MAF criterion on the observed and simulated datasets. This MAF is computed pooling all genes genotyped over all studied population samples. For instance, the specification of a MAF equal to 5% will automatically select a subset of <em>m</em> loci characterized by a minimum allele frequency &gt; 5% out of the <em>l</em> loci of the observed dataset. In agreement with this, only <em>m</em> loci with a MAF&gt;5% will be retained in a simulated dataset. In practice, the instruction for a given MAF has to be indicated directly in the headline of the file of the observed dataset (see section 7.1.1 for data file examples). For instance, if one wants to consider only loci with a MAF equal to 5% one will write &lt;MAF=0.05&gt; in the headline. Writing &lt;MAF=hudson&gt; (or omitting to write any instruction with respect to the MAF) will bring the program to use the standard Hudson's algorithm without further selection. The selection of a subset of loci fitting a given MAF allows: (i) to remove the loci with very low level of polymorphism from the dataset and hence increase the mean level of genetic variation of both the observed and simulated datasets, without producing any bias in the analyses; and (ii) to reduce the proportion of loci for which the observed variation may corresponds to sequencing errors. In practice MAF values ≤10% are considered. To check for the consistency/robustness of the ABC results obtained, it may be useful to treat a SNP dataset considering different MAFs (for instance MAF=hudson, MAF=1% and MAF=5%).</p>
<p>It is worth stressing that the MAF criterion applies to standard Individual sequencing (hereafter <strong>IndSeq</strong>) SNP data. In addition to IndSeq data, DIYABC Random Forest v1.0 allows the simulation and analyses of pool-sequencing SNP data (hereafter <strong>PoolSeq</strong> data), which basically consist of whole-genome sequences of pools of tens to hundreds of individual DNAs (Gautier et al., 2013; Schlötterer et al., 2014). In practice, the simulation of PoolSeq data consists first in simulating individual SNP genotypes for all individuals in each population pool, and then generating pool read counts from a binomial distribution parameterized with the simulated allele counts (obtained from individual SNP genotypes) and the total pool read coverage (e.g., Hivert, et al. 2018). A criterion somewhat similar to the MAF was implemented for PoolSeq data: <u>the minimum read count (MRC)</u>. The MRC is the number of sequence reads of the minor allele frequency allele when pooling the reads over all population samples. The specification of a MRC equal for instance to 5 will automatically select a subset of <em>m</em> PoolSeq loci characterized by more than five reads over all studied pools among the <em>l</em> loci of the observed dataset. In agreement with this, only <em>m</em> loci with more than five reads will be retained in a simulated dataset.</p>
<h2 id="prior-distributions">2.5 Prior distributions</h2>
<p>The Bayesian aspect of the ABC-RF approach implies that parameter estimations use prior knowledge about these parameters that is given by prior distributions of parameters. The program offers a choice among usual probability distributions, i.e. Uniform, Log-Uniform, Normal or Log-Normal for historical parameters and Uniform, Log-Uniform or Gamma for mutation parameters. Extremum values (min and max) and other parameters (e. g. mean and standard deviation) must be filled in by the user. It is worth noting that one can impose some simple conditions on historical parameters. For instance, there can be two times parameters with overlapping prior distributions. However, we want that the first one, say <code>t1</code>, to always be larger than the second one, say <code>t2</code>. For that, we just need to set <code>t1</code> <span class="math inline">&gt;</span> <code>t2</code> in the corresponding edit-windows. Such a condition needs to be between two parameters and more precisely between two parameters of the same category (i.e. two effective sizes, two times or two admixture rates). The limit to the number of conditions is imposed by the logics, not by the program. The only binary relationships accepted here are <span class="math inline">&gt;,&lt;, &gt;  = <em>a</em><em>n</em><em>d</em> &lt; =</span>.</p>
<h2 id="summary-statistics-as-components-of-the-feature-vector">2.6 Summary statistics as components of the feature vector </h2>
<p>The training set includes values of a feature vector which is a multidimensional representation of any data point (i.e. simulated or observed datasets) made up of measurements (or features) taken from it. More specifically, the feature vector includes a large number of statistics that summarize genetic variation in the way that they allow capturing different aspects of gene genealogies and hence various features of molecular patterns generated by selectively neutral population histories (e.g. Beaumont 2010; Cornuet et al. 2014). For each category (microsatellite, DNA sequences or SNP) of loci, the program proposes a series of summary statistics among those used by population geneticists.</p>
<p>Note: The code name of each statistic mentioned in the various program outputs is given between brackets [XXX] in sections 2.6.1, 2.6.2 and 2.6.3.</p>
<h3 id="for-microsatellite-loci">2.6.1 For microsatellite loci</h3>
<div class="Definition-Term">
<p>Single sample statistics:</p>
</div>
<ol type="1">
<li><div class="Definition">
<p>[NAL] - mean number of alleles across loci</p>
</div></li>
<li><div class="Definition">
<p>[HET] - mean gene diversity across loci (Nei 1987)</p>
</div></li>
<li><div class="Definition">
<p>[VAR] - mean allele size variance across loci</p>
</div></li>
<li><p>[MGW] - mean M index across loci (Garza and Williamson 2001; Excoffier et al. 2005)</p></li>
</ol>
<div class="Definition-Term">
<p>Two sample statistics:</p>
</div>
<ol type="1">
<li><div class="Definition">
<p>[N2P] - mean number of alleles across loci (two samples)</p>
</div></li>
<li><div class="Definition">
<p>[H2P] - mean gene diversity across loci (two samples)</p>
</div></li>
<li><div class="Definition">
<p>[V2P] - mean allele size variance across loci (two samples)</p>
</div></li>
<li><div class="Definition">
<p>[FST] -<span class="math inline">  <em>F</em><sub>ST</sub></span> between two samples (Weir and Cockerham 1984)</p>
</div></li>
<li><div class="Definition">
<p>[LIK] - mean index of classification (two samples)</p>
</div></li>
</ol>
<div class="Definition">
<blockquote>
<p>(Rannala and Moutain 1997; Pascual et al. 2007)</p>
</blockquote>
</div>
<ol start="6" type="1">
<li><div class="Definition">
<p>[DAS] - shared allele distance between two samples (Chakraborty and Jin 1993)</p>
</div></li>
<li><div class="Definition">
<p>[DM2] - <span class="math inline">(<em>δ</em><em>μ</em>)<sup>2</sup></span> distance between two samples (Golstein et al. 1995)</p>
</div></li>
</ol>
<div class="Definition-Term">
<p>Three sample statistics:</p>
</div>
<ol type="1">
<li><div class="Definition">
<p>[AML] - Maximum likelihood coefficient of admixture (Choisy et al. 2004)</p>
</div></li>
</ol>
<h3 id="for-dna-sequence-loci">2.6.2 For DNA sequence loci</h3>
<div class="Definition-Term">
<p>Single sample statistics:</p>
</div>
<ol type="1">
<li><div class="Definition">
<p>[NHA] - number of distinct haplotypes</p>
</div></li>
<li><div class="Definition">
<p>[NSS] - number of segregating sites</p>
</div></li>
<li><div class="Definition">
<p>[MPD] - mean pairwise difference</p>
</div></li>
<li><div class="Definition">
<p>[VPD] - variance of the number of pairwise differences</p>
</div></li>
<li><div class="Definition">
<p>[DTA] - Tajima’s D statistics (Tajima 1989)</p>
</div></li>
<li><div class="Definition">
<p>[PSS] - Number of private segregating sites</p>
</div></li>
</ol>
<div class="Definition">
<p>(=number of segregating sites if there is only one sample)</p>
</div>
<ol start="7" type="1">
<li><div class="Definition">
<p>[MNS] - Mean of the numbers of the rarest nucleotide at segregating sites</p>
</div></li>
<li><div class="Definition">
<p>[VNS] - Variance of the numbers of the rarest nucleotide at segregating sites</p>
</div></li>
</ol>
<div class="Definition-Term">
<p>Two sample statistics:</p>
</div>
<ol type="1">
<li><div class="Definition">
<p>[NH2] - number of distinct haplotypes in the pooled sample</p>
</div></li>
<li><div class="Definition">
<p>[NS2] - number of segregating sites in the pooled sample</p>
</div></li>
<li><div class="Definition">
<p>[MP2] - mean of within sample pairwise differences</p>
</div></li>
<li><div class="Definition">
<p>[MPB] - mean of between sample pairwise differences</p>
</div></li>
<li><div class="Definition">
<p>[HST] -<span class="math inline">  F<sub>ST</sub></span> between two samples (Hudson et al. 1992)</p>
</div></li>
</ol>
<div class="Definition-Term">
<blockquote>
<p>Three sample statistics:</p>
</blockquote>
</div>
<ol type="1">
<li><div class="Definition">
<p>[SML] Maximum likelihood coefficient of admixture (adapted from Choisy et al. 2004)</p>
</div></li>
</ol>
<h3 id="for-snp-loci">2.6.3 For SNP loci</h3>
<blockquote>
<p>In addition to “standard” individual-sequencing SNP data (i.e. <strong>IndSeq</strong> data), the program allows the simulation and analyses of pool-sequencing SNP data (i.e. <strong>PoolSeq</strong> data), which basically consist of whole-genome sequences of pools of tens to hundreds of individual DNAs (Gautier et al., 2013; Schlötterer et al., 2014). For both IndSeq and PoolSeq SNPs, we have implemented the following (same) set of summary statistics.</p>
<p>1. [ML1p] [ML2p] [ML3p] [ML4p] - <em>Proportion of monomorphic loci</em> for each population, as well as for each pair, triplet and quadruplet of populations.</p>
<p><strong>Mean (m suffix added to the code name) and variance (v suffix) over loci values are computed for all subsequent summary statistics</strong></p>
<p>2. [HWm] [HWv] [HBm] [HBv] - <em>Heterozygosity</em> for each population and for each pair of populations (Hivert et al. 2018).</p>
<p>3. [FST1m] [FST1v] [FST2m] [FST2v] [FST3m] [FST3v] [FST4m] [FST4v] [FSTGm] [FSTGv] - <em>FST</em>-<em>related statistics</em> for each population (i.e., population-specific FST; Weir &amp; Goudet 2017), for each pair, triplet, quadruplet and overall populations (when the dataset includes more than four populations) (Hivert et al. 2018).</p>
<p>4. [F3m] [F3v] [F4m] [F4v] - <em>Patterson’s f-statistics</em> for each triplet (f3-statistics) and quadruplet (f4-statistics) of populations (Patterson et al. 2012 and Leblois et al. 2018 for the PoolSeq unbiased f3-statistics)</p>
<p>5. [NEIm] [NEIv] - <em>Nei’s (1972) distance</em> for each pair of populations</p>
<p>6. [AMLm] [AMLv] - <em>Maximum likelihood coefficient of admixture</em> computed for each triplet of populations (adapted from Choisy et al. 2004).</p>
</blockquote>
<h2 id="generating-the-training-set">2.7 Generating the training set</h2>
<p>The training set can include as many scenarios as desired. The prior probability of each scenario is uniform so that each scenario will have approximately the same number of simulated datasets. Only parameters that are defined for the drawn scenario are generated from their respective prior distribution. Scenarios may or may not share parameters. When conditions apply to some parameters (see section 2.3), parameter sets are drawn in their respective prior distributions until all conditions are fulfilled. The simulated datasets (summarized with the statistics detailed in section 2.6) of the training set are recorded for further statistical analyses (using Random Forest algorithms) in a key binary file named <u>reftableRF.bin</u>. </p>
<h1 id="random-forest-analysis">3. RANDOM FOREST ANALYSIS</h1>
<h1 id="once-the-training-set-has-been-generated-one-can-start-various-statistical-treatments-using-the-random-forest-rf-algorithms-implemented-in-the-program-and-by-running-the-random-forest-analyses-module.">Once the training set has been generated, one can start various statistical treatments using the Random Forest (RF) algorithms implemented in the program and by running the “Random Forest analyses” module.</h1>
<h1 id="addition-of-linear-combinations-of-summary-statistics-to-the-vector-feature">3.1 Addition of linear combinations of summary statistics to the vector feature </h1>
<p>For scenario choice, the feature vector can be enriched before processing RF predictions (default option that can be disabled) by values of the <em>d</em> axes of a linear discriminant analysis (LDA) processed on the above summary statistics (with <em>d</em> equal to the number of scenarios minus 1; Pudlo et al. 2016). In the same spirit, for parameter estimation, the feature vector can be completed (default option that can be disabled) by values of a subset of the <em>s</em> axes of a Partial Least Squares Regression analysis (PLS) also processed on the above summary statistics (with <em>s</em> equal to the number of summary statistics). The number of PLS axes added to the feature vector is determined as the number of PLS axes providing a given fraction of the maximum amount of variance explained by all PLS axes (i.e., 95% by default, but this parameter can be adjusted). Note that, according to our own experience on this issue, the addition into the feature vector of LDA or PLS axes better extract genetic information from the training set and hence globally improved statistical inferences. While the inferential gain turned out to be systematic and substantial for LDA axes (scenario choice), we found that including PLS axes improved parameter estimation in a heterogeneous way, with a negligible gain in some cases (e.g. Collin et al. 2020).</p>
<h1 id="prediction-using-random-forest-scenario-choice">3.2 Prediction using Random Forest: scenario choice</h1>
<p>For scenario choice, the outcome of the first step of RF prediction applied to a given target dataset is a <u>classification vote for each scenario</u> which represents the number of times a scenario is selected in a forest of <em>n</em> trees. The scenario with the highest classification vote corresponds to the scenario best suited to the target dataset among the set of compared scenarios. This first RF predictor is good enough to select the most likely scenario but not to derive directly the associated posterior probabilities. A second analytical step based on a second Random Forest in regression is necessary to provide an estimation of the <u>posterior probability of the best supported scenario</u> (Pudlo et al. 2016).</p>
<h1 id="prediction-using-random-forest-parameter-estimation">3.3 Prediction using Random Forest: parameter estimation</h1>
<p>For parameter estimation, Raynal et al. (2019) extended the RF approach developed in the context of (non-parametric) regression to estimate the posterior distributions of a given parameter under a given scenario. The approach requires the derivation of a new Random Forest for each component of interest of the parameter vector (i.e. “one parameter, one forest strategy”; Raynal et al. 2019). Quite often, practitioners of Bayesian inference report the posterior mean, posterior variance or posterior quantiles, rather than the full posterior distribution, since the former are easier to interpret than the latter. We implemented in DIYABC Random Forest the methodologies detailed in Raynal et al. (2019) to provide estimations of the <u>posterior mean, variance, median (i.e. 50% quantile) as well as 5% and 95% quantiles (and hence 90% credibility interval) of each parameter of interest</u>. The posterior distribution of each parameter of interest is also inferred using importance weights following Meinshausen (2006)’s work on quantile regression forests.</p>
<h1 id="assessing-the-quality-of-predictions">3.4 Assessing the quality of predictions </h1>
<p>To evaluate the robustness of inferences, DIYABC Random Forest provides:</p>
<ol type="i">
<li><p>Global (i.e. prior) error/accuracy indices corresponding to prediction quality measures computed <em>over the entire data space</em>;</p></li>
<li><p>Local (i.e. posterior) error/accuracy indices computed conditionally on the observed dataset and hence corresponding to prediction quality <em>exactly at the position of the observed dataset</em>.</p></li>
</ol>
<blockquote>
<p>Note that the program used the out-of-bag prediction method for estimating global and local error/accuracy measures (Pudlo et al. 2016; Raynal et al. 2019; Chapuis et al. 2020). This method is computationally efficient as it makes use of the datasets already present in the training set and hence avoids the (computationally costly) simulations of additional test datasets.</p>
</blockquote>
<h3 id="indices-for-scenario-choice">3.4.1 Indices for scenario choice</h3>
<ul>
<li><p><u>Global prior errors</u> including the <em>confusion matrix</em> (i.e. the contingency table of the true and predicted classes – here scenarios - for each example in the training set) and the <em>mean misclassification error rate</em> (over all scenarios).</p></li>
<li><p><u>Local posterior error</u> which corresponds to 1 minus the posterior probability of the selected scenario (Chapuis et al. 2020).</p></li>
</ul>
<h3 id="indices-for-parameter-estimation">3.4.2 Indices for parameter estimation</h3>
<ul>
<li><p><u>Global (prior) and local (posterior) NMAE</u> (i.e. normalized mean absolute error): it is the average absolute difference between the point estimate and the true simulated value divided by the true simulated value, with the mean or the median taken as point estimate.</p></li>
<li><p><u>Global (prior) and local (posterior) MSE and NMSE</u> (i.e. the mean square error): it is the average squared difference between the point estimate and the true simulated value for MSE, divided by the true simulated value for NMSE, again with the mean or the median taken as point estimate.</p></li>
<li><p><u>Several confidence interval measures</u> computed only at the global (prior) scale:</p></li>
</ul>
<blockquote>
<p>- <em>90% coverage</em>: it is the proportion of true simulated values located between the estimated 5% and 95% quantiles.</p>
<p>- <em>Mean or median of the 90% amplitude</em>: it is the mean or median of the difference between the estimated 5% and 95% quantiles.</p>
<p>- <em>Mean or median of the relative 90% amplitude</em>: it is the mean or median of the difference between the estimated 5% and 95% divided by the true simulated value.</p>
</blockquote>
<h1 id="practical-considerations-for-abc-rf-treatments">4. PRACTICAL CONSIDERATIONS FOR ABC-RF TREATMENTS</h1>
<p>Random Forest is often (positively) considered as a “tuning-free” method in the sense that it does not require meticulous calibrations. This represents an important advantage of this method, especially for non-expect users. In practice, we nevertheless advise users to consider several checking points, thereafter formalized as questions, before finalizing inferential treatments using DIYABC Random Forest v1.0.</p>
<h1 id="are-my-scenarios-andor-associated-priors-compatible-with-the-observed-dataset">4.1 Are my scenarios and/or associated priors compatible with the observed dataset?</h1>
<p>This question is of prime interest and applies to ABC-RF as well as to any alternative ABC treatments. This issue is particularly crucial, given that complex scenarios and high dimensional datasets (i.e., large and hence very informative datasets) are becoming the norm in population genomics. Basically, if none of the proposed scenario / prior combinations produces some simulated datasets in a reasonable vicinity of the observed dataset, this is a signal of incompatibility and it is not recommended to attempt any inferences. In such situations, we strongly advise reformulating the compared scenarios and/or the associated prior distributions in order to achieve some compatibility in the above sense. DIYABC Random Forest v1.0 proposes a visual way to address this issue through the simultaneous projection of datasets of the training database and of the observed dataset on the first Linear Discriminant Analysis (LDA) axes. In the LDA projection, the (target) observed dataset has to be reasonably located within the clouds of simulated datasets. The program also proposes some complementary dedicated tools: (i) a Principal Component Analysis (PCA) representing on 2-axes plans the simulated dataset from the training set and the observed dataset; and (ii), <u>for each summary statistics</u>, the proportion of simulated data (considering the total training set) that have a value below the value of the observed dataset. A star indicates proportions lower than 5% or greater than 95% (two stars, &lt;1% or &gt;1%; three stars, &lt;0.1% or &gt;0.1%). The latter numerical results can help users to reformulating the compared scenarios and/or the associated prior distributions in order to achieve some compatibility (see e.g. Cornuet et al. 2010).</p>
<h1 id="did-i-simulate-enough-datasets-for-my-training-set">4.2 Did I simulate enough datasets for my training set?</h1>
<p>A rule of thumb is, for scenario choice to simulate between 2,000 and 20,000 datasets per scenario among those compared (Pudlo et al. 2016; Estoup et al. 2018), and for parameter estimation to simulate between 10,000 and 100,000 datasets under a given scenario (Raynal et al. 2019; Chapuis et al. 2020). To evaluate whether or not this number is sufficient for RF analysis, we recommend to compute error/accuracy metrics such as those proposed by DIYABC Random Forest v1.0 from both the entire training set and a subset of the latter (for instance from a subset of 80,000 simulated datasets if the training set includes a total of 100,000 simulated datasets). If error (accuracy) metrics from the subset are similar, or only slightly higher (lower) than the value obtained from the entire database, one can consider that the training set contains enough simulated datasets. If a substantial difference is observed between both values, then we recommend increasing the number of simulated datasets in the training set.</p>
<h1 id="did-my-forest-grow-enough-trees">4.3 Did my forest grow enough trees?</h1>
<p>According to our experience, a forest made of 500 to 2,000 trees often constitutes an interesting trade-off between computation efficiency and statistical precision (Breiman, 2001; Chapuis et al. 2020; Pudlo et al. 2016; Raynal et al. 2019). To evaluate whether or not this number is sufficient, we recommend plotting error/accuracy metrics as a function of the number of trees in the forest. The shapes of the curves provide a visual diagnostic of whether such key metrics stabilize when the number of trees tends to a given value. DIYABC Random Forest v1.0 provides such a plot-figure as output.</p>
<h1 id="running-example-dataset-treatments-using-the-graphic-user-interface-gui">5. RUNNING (EXAMPLE) DATASET TREATMENTS USING THE GRAPHIC USER INTERFACE (GUI)</h1>
<p><strong>5.1 Launching the GUI</strong></p>
<ul>
<li><p>The GUI can launch the program DIYABC Random Forest with the required parameters and keeps track of the progress of the latter through small log files. A given GUI session (window) allows working on a single project. Several GUI sessions (i.e. several windows) can be launched on a single computer hence allowing working on several projects in parallel. When the computation program has exited abnormally, the GUI issues an error message trying to explain where the program failed.</p></li>
<li><p>Launch the GUI by clicking on the “DIYABC Random Forest” standalone application icon.</p></li>
</ul>
<p>It is worth stressing that the program can also be run locally as any shiny application using R. Moreover, we intend to host soon the program as a web service to provide a DIYABC Random Forest v1.0 server for multiple users.</p>
<p>The main pipeline of DIYABC Random Forest v1.0 is divided into two main modules corresponding to the two main phases, i.e. the simulation and the statistical treatments:</p>
<ul>
<li><p>Module 1 = “<u>Training set simulation</u>” where users specify how simulated data will be generated under the ABC framework to produce a training set.</p></li>
</ul>
<ul>
<li><p>Module 2 = “<u>Random Forest analysis</u>” (necessitating the presence of a training set) which guides users through scenario choice and parameter inference by providing a simple interface for the supervised learning framework based on Random Forest methodologies.</p></li>
</ul>
<p>Note that an additional (second order) module named “<u>Synthetic data file generation</u>” is also available from the GUI. It can be used to easily generate data file(s) corresponding to synthetic “ground truth” raw data (not summarized through statistics) under a given historical scenario and a set of fixed parameter values, for instance for benchmarking purpose. The formats of such simulated data files are the same as those described in section 7.1 for observed (i.e. real) datasets for which one usually wants to make inferences.</p>
<h2 id="what-is-a-diyabc-random-forest-project">5.2 What is a DIYABC Random Forest project?</h2>
<p>DIYABC Random Forest works with projects. A DIYABC Random Forest project is a unit of work materialized by a specific and unique directory that has been named by the users through the interface. A project includes at least one <u>observed dataset</u> and one <u>header file</u> associated to a (already generated or not) <u>training set</u>. The header file, always named <code>header</code><code>RF</code><code>.txt</code>, contains all information necessary to compute a training set associated with the data: i.e. the scenarios, the scenario parameter priors, the characteristics of loci, the loci parameter priors and the list of summary statistics to compute using the <em>Training set simulation</em> module. As soon as the first records of the training set have been simulated, they are saved in the training set file, always named <code>reftable</code><code>RF</code><code>.bin</code> (to keep with the previous name of this key file in the previous standard DIYABC context).</p>
<p>It is worth noting that if one needs to change a scenario or a parameter prior, or a summary statistics, a new project needs to be defined. This is to guarantee that all subsequent actions performed on the project are in coherence with the current data and header files. It is of course strongly advised NOT to manually move files among projects. Incidentally, the <code>header</code><code>RF</code><code>.txt</code> file is only built when the project has been saved, the information progressively input by the user being saved in a series of temporary files. Once a sufficiently large training set has been simulated the different files can be (have to be) zip-saved by the user. Statistical analyses can then be performed using the <em>Random Forest analysis</em> module. The different output files produced by a Random Forest analysis can be (have to be) zip-saved by the user.</p>
<h2 id="main-options-of-the-home-screen">5.3 Main options of the home screen</h2>
<p>When launching the GUI, the home screen appears like this:</p>
<p><img src="media/image15.png" style="width:6.97926in;height:3.92593in" /></p>
<ul>
<li><p>Access to main functionalities: you can access to the two main functionalities of the program (i.e. training set simulation and random forest analyses) in two ways: (i) by clicking on the “launch project” button in the middle of the panel or (ii) by clicking on the “DIYABC-RF main pipeline” button in the upper-left part of the panel.</p></li>
<li><p>Access to other functionalities:</p></li>
</ul>
<ul>
<li><p>To access to the panels allowing generating files corresponding to full in silico datasets (also called pseudo-observed datasets) click on the “Synthetic data file generation” button in the middle of the panel or on the “Synthetic data file generation” Button in the upper-left part of the panel.</p></li>
<li><p>Clicking on the “Preference” button (upper left) gives access to the following screen</p></li>
</ul>
<blockquote>
<p><img src="media/image16.png" style="width:6.5in;height:3.65633in" /></p>
<p>The different options proposed are self-meaning. Default values can be changed by the user. Note that the loop-size option corresponds to the number of simulated datasets distributed over all computer threads and stored in RAM before writing them into the training set file (reftableRF.bin).</p>
</blockquote>
<h2 id="how-to-generate-an-indseq-snp-training-set">5.4 How to generate an IndSeq SNP training set</h2>
<h2 id="step-1-defining-a-new-indseq-snp-project">5.4.1 Step 1: defining a new IndSeq SNP project</h2>
<p>Defining a new project requires different steps which are not strictly the same whether the data are microsatellites/DNA sequences (MSS) or SNP (IndSeq or PoolSeq). Let’s start with an IndSeq SNP project. Click on the “launch project” button in the middle of the panel. The following panel appears.</p>
<p><img src="media/image17.png" style="width:7.53892in;height:4.24074in" /></p>
<ul>
<li><p>Enter a project name in the “Project name” window (here IndSeq_demonstration_project)</p></li>
<li><p>Select the project type (Microsat/sequence or SNP) and the sequencing mode (for SNP only; IndSeq or PoolSeq). Here select SNP and Individual Seq.</p></li>
<li><p>Click on the “New project” button as we want to implement a new project from scratch.</p></li>
</ul>
<h2 id="step-2-choosing-the-data-file">5.4.2 Step 2: choosing the data file</h2>
<ul>
<li><p>Browse and choose a data file (an IndSeq format data file in this case) in the “Data file” window (here INDSNP_sim_dataset_4POP_001.snp). A short summary of the specificities of the loaded datafile appears: here the total number of loci (30000), the minimum allele frequency chosen for simulation (MAF=0.05), the sex ratio indicated by the user (NM=1NF), the total number of individuals and populations, and finally the locus type and their corresponding numbers (A= autosomal, M=mitochondrial,…; see section 7.1 for details about datafile format).</p></li>
</ul>
<blockquote>
<p><img src="media/image18.png" style="width:7.2037in;height:4.05218in" /></p>
</blockquote>
<ul>
<li><p>A “Project set up is ok” message appears at the bottom of the panel if all items have gone correctly. You can then go the next steps. To go to the next step click on the large blue color “Training set simulation” “+” button”. The following panel appears.</p></li>
</ul>
<p><img src="media/image19.png" style="width:7.56481in;height:4.25531in" /></p>
<h2 id="step-3-inform-the-historical-model">5.4.3 Step 3: Inform the Historical model</h2>
<p>Click on the “Add” button of the “Define historical models” section. The following panel appears:</p>
<p><img src="media/image20.png" style="width:7.39077in;height:4.15741in" /></p>
<p>Write the code of a first scenario (scenario 1) in the ”Describe your scenario” edit window.</p>
<p>We get this:<br />
<img src="media/image21.png" style="width:7.39077in;height:4.15741in" /></p>
<p>• If we click on the “Draw scenario” button, the logic of the scenario is checked and if it is found OK, and if the scenario is draw-able, the drawing appears on a new frame. The graphical representation of the scenario can be saved by clicking on the “Save image” button.</p>
<p>The “Priors and conditions” frame allows choosing the prior density of each parameter of the scenario. A parameter is anything in the scenario that is not a keyword (here <code>sample</code>, <code>merge</code><code> and split</code>), nor a numeric value. In our example scenario, parameters are hence: <code>N1, N2, N3,</code><code> N4, ra,</code><code> t</code><code>2</code><code>1</code><code>, t32</code> and <code>t431</code>. We choose a uniform distribution and change the min and max values of the different parameters (see panel below). In our example, we need to set the priors on <code>t21, t32 and t431 such that </code>t21&gt;t32 and t431&lt;t32.</p>
<p><img src="media/image22.png" style="width:7.57184in;height:4.25926in" /></p>
<p>To do this we write t21&gt;t32 and t431&lt;t32 on two successive lines in the “Condition setting” frame. As noted in the panel, conditions should have the following format: XX&lt;YY. where ‘XX' and 'YY' are parameters of the same type. You can use the standard comparison signs: '&gt;', '&gt;=', '&lt;', '=&lt;'. It is worth stressing that the omission of such conditional constraints on merge times (cf. a population needs to exist in the past to allow coalescence events in it) is one of the most frequent implementation error made by DIYABC Random Forest users. If forgotten a "gene genealogy failure" message pointing to the problematic scenario will appear when launching simulations. Note that the occurrence of a too large number of time conditional constraints within a scenario may substantially slow down simulations as a valid t parameter vector will be retain and run only once all conditions are fulfilled.</p>
<ul>
<li><p>We then can <u>add some other scenarios in additional windows</u> by clicking on the button “Add scenario” (one or several times if one wants to add a single or several other scenarios). In the present example, we simulate datasets from six different scenarios that we want to compare (see Collin et al. 2020 for details), hence the six scenario windows that we have completed with instructions for each scenario. For the sixth scenario the panel looks like this:</p></li>
</ul>
<p><img src="media/image23.png" style="width:7.70352in;height:4.33333in" /></p>
<p><strong>5.4.4 Step 4: Inform chromosome type and number of loci</strong></p>
<p>Choose the number of SNP locus that you want to simulate for each chromosome type define in the data file. Here we have only type &lt;A&gt; SNP loci that correspond to SNPs located on autosomal chromosomes. According to our own experience, analyzing (evolutionary neutral) scenarios using 5000, 10000 or 20000 SNP loci is sufficient to obtain robust results. In this example, we choose to consider simulations based on a subset of 5000 SNP loci (with MAF=0.05 as indicated previously) taken in order from the first SNP locus of the data file, by replacing 30000 by 5000 in the corresponding frame. It is worth stressing that choosing a subset of 5000 SNP loci taken from the SNP locus 5001 of the data file would lead to a training set generated from a set of 5000 loci completely independent from the previous one. Generating by this way different training sets is a way to process independent analyses of a given dataset (a sufficiently large number of SNP loci available in the observed dataset is obviously needed to do that).</p>
<p><img src="media/image24.png" style="width:7.63768in;height:4.2963in" /></p>
<p><strong>5.4.5 Step 5: Summary statistics</strong></p>
<p>In the present version of the program, all available summary statistics are computed. When you click on the “Summary statistics” button, the following text message appears.</p>
<blockquote>
<p>WARNING! ALL SUMMARY STATISTICS IMPLEMENTED IN THE PROGRAM WILL BE COMPUTED AND INCLUDED IN THE TRAINING SET</p>
<p>For both IndSeq and PoolSeq SNP loci, the following set of summary statistics has been implemented.</p>
<p>1. <em>Proportion of monomorphic loci</em> for each population, as well as for each pair and triplet of populations (ML1p, ML2p, ML3p)</p>
<p><strong>Mean and variance (over loci) values are computed for all subsequent summary statistics.</strong></p>
<p>2. <em>Heterozygosity</em> for each population (HW) and for each pair of populations (HB)</p>
<p>3. <em>FST</em>-<em>related statistics</em> for each population (FST1), for each pair (FST2), triplet (FST3), quadruplet (FST4) and overall (FSTG) populations (when the dataset includes more than four populations)</p>
<p>4. <em>Patterson’s f-statistics</em> for each triplet (f3-statistics; F3) and quadruplet (f4-statistics; F4) of populations</p>
<p>5. <em>Nei’s distance</em> (NEI) for each pair of populations</p>
<p>6. <em>Maximum likelihood coefficient of admixture</em> (AML) computed for each triplet of populations.</p>
<p>Note the short code name for each type of summary statistics (MLP1p, HW, FST2, F3,…). Such code names of statistics (plus the suffix m and v for mean and variance over loci, respectively; see section 2.6.3) will be used in most files produced by the program, including the key files headerRF.txt, reftableRF.bin and statobsRF.txt.</p>
</blockquote>
<h2 id="step-6-simulate-the-training-set">5.4.6 Step 6: Simulate the training set</h2>
<p>Click on the large blue “Training set simulation” “+” button. The following “Run” panel appears.</p>
<p><img src="media/image25.png" style="width:7.61111in;height:4.28135in" /></p>
<ul>
<li><p>Indicate the required number of datasets to simulate in the training set (here 12000 and hence 2000 simulated datasets for each of the six scenarios)</p></li>
<li><p>You can activate the “Run prior and scenario checking” option; see further explanation about this option in the next section 5.4.7 Step 7 (optional but recommended) - Scenario-priors checking PRE-ANALYSIS</p></li>
<li><p>Launch the generation of the simulated datasets of the training set by clicking on the “Simulate” button. The number of datasets already simulated is given in the progress bar below.</p></li>
</ul>
<p>“mettre panel illustratif adapté !!!!!”</p>
<ul>
<li><p>You can stop the generation of simulated datasets by clicking on the “STOP” button. A “Simulation terminated” label appears when all requested simulations have been processed.</p></li>
<li><p>Do not forget to click on the “Save” button in the “Project housekeeping” panel to save a concatenated .zip file including various input and output files (see section 7 for a description of the content of some of those files) on your computer. The name of the concatenated .zip file is the one given at the start in the “Project name” window.</p></li>
</ul>
<p><img src="media/image26.png" style="width:7.25909in;height:4.08333in" /></p>
<ul>
<li><p>Warning: The button “Reset” in the “Project housekeeping” panel restart the pipeline from scratch removing all instructions previously entered.</p></li>
</ul>
<h2 id="step-7-optional-but-recommended-prior-scenario-checking-pre-analysis">5.4.7 Step 7 (optional but recommended): Prior-scenario checking PRE-ANALYSIS</h2>
<p>Before performing a full ABC-RF analysis on a large size training set, we advise using the prior-scenario checking option on a training set of small size (e.g. including 500 to 1000 simulated dataset per scenarios). As a matter of fact, this pre-analysis option is a convenient way to reveal potential mispecification of models (scenarios) and/or prior distributions of parameters (and correct it). When the “prior and scenario checking” option is activated (before launching the generation of the training set; cf. previous section 5.4.6), the program will then use the statobsRF.txt and reftableRF.bin files to generate two specific outputs:</p>
<ul>
<li><p>A Principal Component Analysis (PCA) representing on 2-axes plans the simulated dataset from the training set and the observed dataset as graphical output. Note that this figure is somewhat similar in its spirit to the graphical output LDA_training_set_and_obs_dataset.png obtained when running the scenario choice option in “Random Forest Analyses”. The latter output is different, however, as it corresponds to the projection of the datasets from the training set linear discriminant analysis (LDA) axes (see section 7.3 for details).</p></li>
<li><p>A numerical output file, named pcaloc1_locate.txt, which includes for each summary statistics and for each scenario, the proportion of simulated data (considering the total training set) that have a summary statistics value below the value of the observed dataset. A star indicates proportions lower than 5% or greater than 95% (two stars, &lt;1% or &gt;1%; three stars, &lt;0.1% or &gt;0.1%). The presence of such star symbols is a sign of substantial mismatch between the observed dataset and the simulated datasets. The latter numerical results can help users to reformulating the compared scenarios and/or the associated prior distributions in order to achieve some compatibility (see e.g. Cornuet et al. 2010). If only a few stars are observed at a few summary statistics for one or several scenarios, one can conclude that prior-scenario conditions are suitable enough to further process Random Forest analysis, and this potentially on a training set including more simulated datasets.</p></li>
</ul>
<h2 id="how-to-generate-a-poolseq-snp-training-set">5.5 How to generate a PoolSeq SNP training set</h2>
<p>Follow the same five steps described in section 5.4 for IndSeq SNPs.</p>
<ul>
<li><p><em>Step 1</em>: Defining a new PoolSeq SNP project see section 5.4.1</p></li>
</ul>
<p>Click on the “Launch project” button of the home screen. Select SNP as project type and PoolSeq as sequencing mode</p>
<ul>
<li><p><em>Step 2</em>: Choosing the data file see section 5.4.2 and select a dataset file characterized by a PoolSeq format (format detailed in section 7.1.2).</p></li>
<li><p><em>Step 3</em>: Inform the Historical model see section 5.4.3</p></li>
<li><p><em>Step 4</em>: Inform chromosome type and number of loci see section 5.4.4</p></li>
</ul>
<p>Note: The panel for PoolSeq SNPs is simpler than for IndSeq SNPs because PoolSeq SNPs are considered as located on <strong>autosomal chromosomes only</strong>.</p>
<ul>
<li><p><em>Step 5</em>: Define summary statistics: see section 5.4.5</p></li>
<li><p><em>Step 6</em>: Simulate the training set see section 5.4.6</p></li>
<li><p><em>Step 7</em> (optional but recommended): Prior-scenario checking PRE-ANALYSIS see section 5.4.7</p></li>
</ul>
<h2 id="how-to-generate-a-microsatellite-andor-sequence-training-set">5.6 How to generate a microsatellite (and/or sequence) training set</h2>
<p>Follow the same steps described in section 5.4 for IndSeq SNPs.</p>
<ul>
<li><p><em>Step 1</em>: Defining a new or microsatellites/DNA sequences project see section 5.4.1</p></li>
</ul>
<blockquote>
<p>Click on the “Launch project” button of the home screen. Select Microsat/Sequences as project type (not any sequencing mode is needed)</p>
</blockquote>
<ul>
<li><p><em>Step 2</em>: Choosing the data file see section 5.4.2 and select a dataset file characterized by a Microsatellite and/or DNA Sequences format (format detailed in section 7.1.3).</p></li>
<li><p><em>Step 3</em>: Inform the Historical model see section 5.4.3</p></li>
<li><p><strong><em>Step 4</em>: The panel “Inform chromosome type and number of loci” is replaced by the panel “Inform the genetic model” see details below in section 5.6.1</strong></p></li>
</ul>
<p>METTRE DANS LA SECTION 5.6.1 UN EXEMPLE DE PANNEL POUR MICROSAT ET UN EXEMPLE DE PANNEL POUR SEQUENCES (avec des explications)</p>
<ul>
<li><p><strong><em>Step 5</em>: Summary statistics: the corresponding panel points to different sets of summary statistics as compared to SNP summary statistics see details below in section 5.6.2</strong></p></li>
<li><p><em>Step 6</em>: Simulate the training set see section 5.4.6</p></li>
<li><p><em>Step 7</em> (optional but recommended): Prior-scenario checking PRE-ANALYSIS see section 5.4.7</p></li>
</ul>
<h3 id="step-4-inform-the-genetic-model">5.6.1 Step 4: Inform the genetic model </h3>
<p>Click on the corresponding “Genetic model” button. We get the following screen:<br />
<img src="media/image27.png" style="width:4.375in;height:3.19792in" alt="image" /></p>
<p>On the left part of the screen, there is the list of loci, with their type (M for microsatellites or S for DNA sequences) and the motif size and allelic range for microsatellite loci only. Actually, the values for motif size and allelic range are just default values and do not necessarily correspond to the actual data. The user who knows the real values for its data is required to set the correct values at this stage. If the range is too short to include all values observed in the analyzed dataset, a message appears in a box asking to enlarge the corresponding allelic range. Note that the allelic range is measured in number of motifs, so that a range of 40 for a motif length of 2 bp means that the difference between the smallest and the longest alleles should not exceed 80 bp. It is worth stressing that the indicated allelic range (expressed in number of continuous allelic states) corresponds to a potential range which is usually larger than the range observed from the analyzed dataset (cf. all possible allelic states have usually not been sampled). In practice it is difficult to assess the actual microsatellite constraints on the allelic range; to do that one needs allelic data from several distantly related populations/sub-species as well as related species which is rarely the case(see Pollack et al. 1998; Estoup et al. 2002). We achieved a meta-analysis from numerous primer notes documenting the microsatellite allelic ranges of many (i.e. &gt; 100) different species (and related species). We used the corrective statistical treatment on such data proposed by (Pollack et al. 1998). Our results pointed to a mean microsatellite allelic range of 40 continuous states (hence the default allelic range value of 40 mentioned in the program). We also found, however, that range values greatly varied among species and among loci within species (unpublished results). We therefore recommend the following pragmatic behavior when considering the allelic range of your analysed microsatellite dataset: (i) if the difference in number of motif of your locus is &lt; 40 motifs in the analysed dataset then leave the default allelic range value of 40. (ii) if the difference in number of motif of your locus is &gt;40 motifs in your dataset then take Max_allele_size <span class="math inline">−</span> Min_allele_size)/motif size + say 10 additional motifs to re-define the allelic range of the locus in the corresponding DIYABC panel (e.g. (200 nu <span class="math inline">−</span> 100 nu)/2 + 10 = 50 + 10 = 60 as allelic range).</p>
<p>We then need to define at least one group of loci by clicking on the button. We get this:<br />
<img src="media/image28.png" style="width:4.41667in;height:3.36458in" alt="image" /></p>
<p>Suppose we want all loci in the same group because we consider that they all have similar mutational modalities. We select them like in any table, extending the selection with the <code>Shift</code> and <code>Control</code> keys (see below):<br />
<img src="media/image29.png" style="width:4.53125in;height:3.46875in" alt="image" /></p>
<p>and then pressing the button:<br />
<img src="media/image30.png" style="width:4.51042in;height:3.45833in" alt="image" /></p>
<p>Note that the button would have produced the same result of putting all the microsatellite loci in the same group. We then need to define the mutation model and the summary statistics of the locus group. Clicking on the button, the following screen appears:<br />
<img src="media/image31.png" style="width:4.22917in;height:3.26042in" alt="image" /></p>
<h3 id="step-5-summary-statistics">5.6.2 Step 5: Summary statistics</h3>
<p>In the present version of the program, all available summary statistics are computed. When you click on the “Summary statistics” button, the following text message appears.</p>
<p><strong><u>For microsatellite loci</u></strong></p>
<blockquote>
<p>WARNING! ALL SUMMARY STATISTICS IMPLEMENTED IN THE PROGRAM WILL BE COMPUTED AND INCLUDED IN THE TRAINING DATASET</p>
<p>For microsatellite loci, the following set of summary statistics has been implemented.</p>
</blockquote>
<dl>
<dt>Single sample statistics:</dt>
<dd><p>1. mean number of alleles across loci (NAL)</p>
<p>2. mean gene diversity across loci (HET)</p>
<p>3. mean allele size variance across loci (VAR)</p>
</dd>
</dl>
<p>3. mean M index across loci (MGW)</p>
<dl>
<dt>Two sample statistics:</dt>
<dd><p>1. mean number of alleles across loci (two samples) (N2P)</p>
<p>2. mean gene diversity across loci (two samples) (H2P)</p>
<p>3. mean allele size variance across loci (two samples) (V2P)</p>
<p><span class="math inline">3. <em>F</em><sub>ST</sub></span> between two samples (FST)</p>
<p>4. mean index of classification (two samples) (LIK)</p>
<p>5. shared allele distance between two samples (DAS)</p>
<p>6.<span class="math inline"> (<em>δ</em><em>μ</em>)<sup>2</sup></span> distance between two samples (DM2)</p>
</dd>
<dt>Three sample statistics:</dt>
<dd><p>1. Maximum likelihood coefficient of admixture (AML)</p>
</dd>
</dl>
<p><strong><u>For DNA sequence loci</u></strong></p>
<blockquote>
<p>WARNING! ALL SUMMARY STATISTICS IMPLEMENTED IN THE PROGRAM WILL BE COMPUTED AND INCLUDED IN THE TRAINING DATASET</p>
<p>For DNA sequence loci, the following set of summary statistics has been implemented.</p>
</blockquote>
<dl>
<dt>Single sample statistics:</dt>
<dd><p>1. number of distinct haplotypes (NHA)</p>
<p>2. number of segregating sites (NSS)</p>
<p>3. mean pairwise difference (MPD)</p>
<p>4. variance of the number of pairwise differences (VPD)</p>
<p>5. Tajima’s D statistics (DTA)</p>
<p>6. Number of private segregating sites (PSS)</p>
<p>7. Mean of the numbers of the rarest nucleotide at segregating sites (MNS)</p>
<p>8. Variance of the numbers of the rarest nucleotide at segregating sites (VNS)</p>
</dd>
<dt>Two sample statistics:</dt>
<dd><p>1. number of distinct haplotypes in the pooled sample (NH2)</p>
<p>2. number of segregating sites in the pooled sample (NS2)</p>
<p>3. mean of within sample pairwise differences (MP2)</p>
<p>4. mean of between sample pairwise differences (MPB)</p>
<p><span class="math inline">5. <em>F</em><sub>ST</sub></span> between two samples (HST)</p>
</dd>
<dt></dt>
<dd><p>1. Maximum likelihood coefficient of admixture (SML)</p>
</dd>
</dl>
<h1 id="performing-random-forest-analyses">6. PERFORMING RANDOM FOREST ANALYSES</h1>
<h2 id="files-needed">6.1 Files needed</h2>
<p>Three files are needed at this stage:</p>
<ul>
<li><p>the file <strong>headerRF.txt</strong> which describes the full settings of the generation of the training set</p></li>
<li><p>the training set file <strong>reftableRF.bin</strong> (generated from the headerRF.txt file),</p></li>
<li><p>the file <strong>statobsRF.txt</strong> which corresponds to the values of the summary statistics computed for the observed dataset and which was generated when producing the headerRF.txt and reftableRF.bin files.</p></li>
<li><p>Note: although not necessary for Random Forest analyses as the later only need the statobsRF.txt file as data point to analyze, the SNP data file has to be present or loaded using the corresponding “Data file” browser.</p></li>
<li><p>These files are already available in an in course analysis or can be loaded independently by clicking on the “Existing project” button and using the browser of the ”Project files” item.</p></li>
</ul>
<p><img src="media/image32.png" style="width:7.73148in;height:4.34906in" /></p>
<h2 id="scenario-choice-analysis">6.2. Scenario choice analysis</h2>
<ul>
<li><p>Click on the large orange color “Random Forest Analyses” button (“+” on the right). The panel looks like this.</p></li>
</ul>
<p><img src="media/image33.png" style="width:6.53194in;height:3.67431in" /></p>
<ul>
<li><p>Useful information about the training set (cf. reftableRF.bin file) content is provided (total nbr of simulated datasets, nbr of scenarios, nbr of parameters, nbr of summary statistics). The observed dataset that will be analyzed is the one described in the file “statobsRF.txt”.</p></li>
<li><p>Activate the “Scenario choice” button in the mode setting (button activated by default)</p></li>
<li><p>Indicate the number of simulated datasets in the training set to consider for analyses (default = total number of simulated datasets available in the training set). This number should be lower or equal to the total number of simulated datasets available in the training set.</p></li>
<li><p>Indicate the number of noise variables to add (default = 5). Noise variables (corresponding to values randomly drawn into uniform distributions bounded between 0 and 1) allows evaluating which components of the feature vector (i.e. summary statistics) are informative (see section 7.3 and Collin et al. 2020 for details).</p></li>
<li><p>Enable/disable the addition of linear combinations axes (LDA for model choice) (default = enable)</p></li>
<li><p>Click on the button “RUN” to launch the RF scenario choice analysis</p></li>
</ul>
<blockquote>
<p>“mettre ici panel illustratif adapté”</p>
</blockquote>
<ul>
<li><p>Follow the progress bar. You can stop the RF analysis by clicking on the “STOP” button. A “RF analyses terminated” label appears when the RF analysis has been entirely processed.</p></li>
<li><p>Do not forget to click on the “Save” button in the “Project housekeeping” panel to save a concatenated .zip file including various input and output files (see section 7 for a description of the content of some of those files) on your computer. The name of the concatenated .zip file is the one given at the start in the “Project name” window.</p></li>
</ul>
<h2 id="parameter-estimation-analysis">6.3. Parameter estimation analysis</h2>
<ul>
<li><p>Click on the large orange color “Random Forest Analyses” button (“+” on the right).</p></li>
<li><p>Useful information about the training set (cf. reftableRF.bin file) content is provided (total nbr of simulated datasets, nbr of scenarios, nbr of parameters, nbr of summary statistics). The observed dataset that will be analyzed is the one described in the file “statobsRF.txt”.</p></li>
<li><p>Activate the “Parameter estimation” button in the mode setting. The panel then looks like this.</p></li>
</ul>
<p><img src="media/image34.png" style="width:8.32902in;height:4.68518in" /></p>
<ul>
<li><p>Indicate the Scenario ID number for parameter estimation (default = 1)</p></li>
<li><p>Indicate the name of the parameter to estimate: a list of parameter names available for estimation according to the header and training set files is provided. Give a single name or a combination of names as explained in the interface. One analysis has to be processed for each parameter of interest.</p></li>
</ul>
<blockquote>
<p><img src="media/image35.png" style="width:7.78582in;height:4.37963in" /></p>
</blockquote>
<ul>
<li><p>Indicate the number of simulated datasets in the training set to consider for analyses (default = 10000). This number should be lower or equal to the total number of simulated datasets available for the chosen scenario in the training set.</p></li>
<li><p>Indicate the number of noise variables to add (default = 5)</p></li>
<li><p>Enable/Disable the addition of linear combinations axes (PLS for parameter estimation) (default = enable)</p></li>
<li><p>Indicate the number of out-of-bag (oob) testing samples (default = 1000). This number should be equal or lower to the number of datasets available in the training set for the scenario under study.</p></li>
<li><p>Click on the button “RUN” to launch the parameter estimation analyses focusing on the single parameter (or parameter combination) indicated above.</p></li>
</ul>
<blockquote>
<p>“mettre ici panel illustratif adapté”</p>
</blockquote>
<ul>
<li><p>Follow the progress bar. You can stop the RF analysis by clicking on the “STOP” button. A “RF analyses terminated” label appears when the RF analysis has been entirely processed.</p></li>
<li><p>Do not forget to click on the “Save” button in the “Project housekeeping” panel to save a concatenated .zip file including various input and output files (see section 7 for a description of the content of some of those files) on your computer. The name of the concatenated .zip file is the one given at the start in the “Project name” window.</p></li>
</ul>
<h1 id="key-files">7. KEY FILES</h1>
<p>The program uses and produces various files which we will describe now.</p>
<h2 id="data-files">7.1 Data files </h2>
<p><strong>7.1.1 IndSeq SNP data</strong></p>
<p>The data file format includes:</p>
<ul>
<li><p>A first line (headline) providing the sex-ratio as above (e.g. <span class="math inline"> &lt; <em>N</em><em>M</em> = 1.0<em>N</em><em>F</em>&gt;</span>), the required MAF (minimum allele frequency criterion; e.g. <span class="math inline">&lt;</span>MAF=0.05<span class="math inline">&gt;</span> or <span class="math inline">&lt;</span>MAF=hudson&gt;), and any text that can be used as a title. The sex ratio of the analyzed species is noted under the form &lt;NM=rNF&gt;, in which r is the ratio of the number of females per male (e.g. &lt;NM=2.5NF&gt; means that the number of males is 2.5 times the number of females; for a balanced sex ratio one should write &lt;NM=1.0NF&gt;). The MAF is computed pooling all genes genotyped over all studied population samples. For instance, the specification of a MAF equal to 5% (i.e. <span class="math inline">&lt;</span>MAF=0.05<span class="math inline">&gt;</span>) will automatically select a subset of m loci characterized by a minimum allele frequency <span class="math inline">&gt;</span> 5% among the <em>l</em> locus of the observed dataset. In agreement with this, only <em>m</em> locus with a MAF&gt;5%. Writing &lt;MAF = Hudson&gt; (or omitting to write any instruction with respect to the MAF) will bring the program to use the standard Hudson’s algorithm without further selection; see also the above section 2.4.2.</p></li>
<li><p>A second line starting with the three keywords <code>IND SEX POP</code>, separated by at least one space, followed by as many letters as SNP loci, the letter giving the location of the locus as above <em>A</em> for autosomal diploid loci, <em>H</em> for autosomal haploid loci, <em>X</em> for X-linked (or haplo-diploid) loci, <em>Y</em> for Y-linked loci and <em>M</em> for mitochondrial loci. Letters are separated by a single space.</p></li>
<li><p>As many lines as there are genotyped individuals, with the code-name of the individual, a letter (M or F; or 9 if the sex of the individual is unknown) indicating its sex, and a code-name for its population. <strong><u>A genotype is defined by the values 0, 1 or 2 which correspond to the number of the (arbitrarily chosen) reference allele composing the genotype</u></strong><u> </u>at each SNP locus. For instance in the case autosomal diploid SNP loci (denoted A), we have: 2 = homozygous genotype for the reference allele (cf. 2 copies of the reference allele), 1 = heterozygous genotype (cf. 1 copy of the reference allele), and 0 = homozygous genotype for the variant allele, with 0 copy of the reference allele. <u>It is worth noting that for autosomal haploid loci (denoted H), as well as for mitochondrial loci (denoted M) and Y-linked loci (denoted Y), the SNP genotypes will be 0 or 1, which is coherent with our logic of defining a genotype according to the number of the reference allele composing the genotype.</u></p></li>
<li><p>Missing SNP genotypes are noted 9 for all type of SNP loci.</p></li>
<li><p>Only a subset of the SNP loci included in the data file can be considered (selected) in the simulations and hence in subsequent analyses, without modifying the original dataset. For instance one can choose to select in the corresponding panel the SNP loci 1 to 1000 of a data file including a total of say 10000 loci (see the above section 5.4.4). This allows running faster simulations and processing independent replicate analyses of sets of 1000 SNP loci by considering loci 1 to 1000 and then 1001 to 2000, and so on, in separate analyses.</p></li>
<li><p>Following Hudson’s (2002) criterion, only polymorphic SNP loci (over the entire dataset) are considered. Monomorphic SNP loci (over the entire dataset) are automatically filtered by the program. It is preferable, however, that the user removes himself all monomorphic loci from his/her (observed) dataset before submitting it to DIYABC Random Forest.</p></li>
<li><p>Before running any simulation, DIYABC Random Forest provides a text file including the set of SNP loci selected from the observed dataset (e.g. polymorphic loci 1 to 1000 with a MAF=0.05). This file is named “UserDataFileName.bin.txt”.</p></li>
</ul>
<p><strong>EXAMPLE</strong></p>
<p>In our example below, the species is diploid, has an unbalanced sex ration the sex-ratio as above (i.e. &lt;NM=1.5NF&gt;) and two of its populations were genotyped at 23 SNP loci: 20 autosomal loci, 1 X-linked locus, 1 Y-linked locus and 1 mitochondrial locus. The first line provides the title which includes the species sex-ratio and the MAF (minimum allele frequency). The second line indicates: individual name in column 1, individual sex in column 2 (<code>M</code> for male, <code>F</code> for female, <code>9</code> or any other letter if unknown), population name in column 3 and one column per SNP locus (letter <code>A</code> for an autosomal locus, <code>X</code> for an X-linked locus, <code>Y</code> for a Y-linked locus and <code>M</code> for a mitochondrial locus). Columns are separated by one or more spaces. SNP genotypes are coded <code>0</code>, <code>1</code> or <code>2</code> (<code>9</code> for missing data) according to the number of reference alleles at the corresponding locus. Note that the sex has no influence on simulations for autosomal, mitochondrial or haploid loci (any sex can be hence declared). For individuals with an unknown sex (denoted <code>9</code>, see <code>IND P1_2, P1_3 and P2_15),</code> data for autosomal (as well as mitochondrial and haploid) loci will be taken into account and simulated. On the other hand, the genotypes of X-linked and Y-linked loci for the <code>same IND P1_2, P1_3 and P2_15</code> with unknown sex cannot be safely determined and are hence noted <code>9</code> for missing data (i.e. they are not simulated).</p>
<p><img src="media/image36.png" style="width:4.83333in;height:4.35417in" alt="image" /></p>
<p><strong>7.1.2 PoolSeq SNP data</strong></p>
<p>The data file format includes:</p>
<ul>
<li><p>A first line (headline) providing the sex-ratio of the analyzed species (e.g.&lt;NM=1.0NF&gt;), the required MRC (minimum read count criterion; e.g. &lt;MRC=5&gt;), and any text that can be used as a title. The sex ratio is noted under the form &lt;NM=rNF&gt;, in which r is the ratio of the number of females per male (e.g. &lt;NM=2.5NF&gt; means that the number of males is 2.5 times the number of females; for a balanced sex ratio one should write &lt;NM=1.0NF&gt;). The MRC is the number of sequence reads of the minor allele frequency allele when pooling the reads over all population samples. The specification of a MRC equal for instance to 5 (as in the present example) will automatically select a subset of <em>m</em> PoolSeq loci characterized by more than five reads over all studied pools among the l loci of the observed dataset. For instance the first locus of the list (cf. third line of the file) will not be selected. In agreement with this, only <em>m</em> loci with more than five reads will be retained in a simulated dataset. We advise using MRC values of 2, 3, 4 or 5.</p></li>
<li><p>Remember that (in contrast to IndSeq SNP) only PoolSeq SNPs located on autosomal chromosomes of diploid individuals can be considered by the program.</p></li>
<li><p>A second line provides the haploid sample size of each population pool.</p></li>
<li><p>The following lines correspond to the PoolSeq SNP genotypes (given in read counts). Each line represents a SNP and each pair of columns points to a population pool in the same order as in the second line. For each SNP-pool combination, the number of read counts is indicated for the first and second allele in the first and second column, respectively.</p></li>
<li><p>Warning: no missing data (i.e. “0 0” data; cf. no read count for any allele) is allowed in the PoolSeq data file and this for any pools in the data file.</p></li>
<li><p>We advise to put only SNP loci with a coverage &gt; 10 reads for each analyzed pool of the dataset in order to ensure descent allele frequency estimation within each pool. SNP loci with an abnormally high coverage should be also removed as those loci can be duplicated loci.</p></li>
<li><p>Only a subset of the SNP loci included in the data file can be considered (selected) in the simulations and hence in subsequent analyses, without modifying the original dataset. For instance one can choose to select in the corresponding panel the SNP loci 1 to 1000 of a data file including a total of say 10000 loci (see the above section 5.4.4). This allows running faster simulations and processing independent replicate analyses of sets of 1000 SNP loci by considering loci 1 to 1000 and then 1001 to 2000, and so on, in separate analyses.</p></li>
</ul>
<p><strong>EXAMPLE</strong></p>
<p>In our example below, the species is diploid and was genotyped using the PoolSeq technology at several thousands of autosomal SNPs in four population pools; <u>only the first 13 SNPs are shown here </u>for sake of concision. The species sex-ratio is balanced and hence equal 1 and the MRC (minimum read count) is 5. Each population pool is composed of 100 diploid individuals (haploid sample size = 200). The second line provides the haploid sample size of each population pool. It has to start with the explicit terminology POOL POP_NAME:HAPLOID_SAMPLE_SIZE. Here the haploid sample size is 200 for each “POPx”. Note that you can write any sample name, e.g. MONTPELLIER, instead of POPx. Columns are separated by one or more spaces. Each line represents a SNP (hence the 13 lines) and each pair of columns points to a population pool (hence the 4 pairs of column). For each SNP-pool combination, the number of read counts is indicated for the first and second allele in the first and second column, respectively. For instance, we have 2 reads of the first allele and 114 reads of the second allele for the first SNP genotyped in the POOL-POP3. Note that because the MRC=5 several SNP of the present example data file, e.g. the first SNP for which only two read counts are present over all pools, will not be selected when generating simulated datasets.</p>
<p><img src="media/image37.emf" style="width:6.52597in;height:4.35417in" /></p>
<p><strong>7.1.3 Microsatellite and DNA sequence data</strong></p>
<p>The data file format is an extended format of the file used in the classical population genetics program Genepop (Rousset et al. 1995). The additional features are:</p>
<ul>
<li><p>In the title line appears the sex ratio noted <span class="math inline"> &lt; <em>N</em><em>M</em> = <em>r</em><em>N</em><em>F</em>&gt;</span>, in which <span class="math inline"><em>r</em></span> is the ratio of the number of females per male (<span class="math inline">e.g.</span> <span class="math inline"> &lt; <em>N</em><em>M</em> = 2.5<em>N</em><em>F</em>&gt;</span> means that the number of males is 2.5 times the number of females; for a balanced sex ratio one should write <span class="math inline"> &lt; <em>N</em><em>M</em> = 1.0<em>N</em><em>F</em>&gt;</span>). Since the title is generally only copied, this addition should not interfere with other programs using Genepop datafiles. Also if there is no such sex ratio addition, DIYABC will consider by default that NM=1.0NF.</p></li>
<li><p>After the locus name, there is an indication for the category of the locus which is <span class="math inline"> &lt; <em>A</em>&gt;</span> for autosomal diploid loci, <span class="math inline"> &lt; <em>H</em>&gt;</span> for autosomal haploid loci, <span class="math inline"> &lt; <em>X</em>&gt;</span> for X-linked (or haplo-diploid) loci, <span class="math inline"> &lt; <em>Y</em>&gt;</span> for Y-linked loci and <span class="math inline"> &lt; <em>M</em>&gt;</span> for mitochondrial loci. If no category is noted, DIYABC will consider the locus as autosomal diploid or autosomal haploid depending on the corresponding genotype of the first typed individual.</p></li>
<li><p>Genotypes of microsatellite loci are noted with <strong>six digit numbers</strong> if diploid (e.g. 190188 for a heterozygous genotype with one allele 190 and one allele 188, and 200200 for a homozygous genotype with two alleles 200) and by <strong>three digit numbers</strong> (e.g. 190) if haploid. <u>The three digit numbers corresponds to the length in nucleotides of the corresponding PCR products</u>.</p></li>
<li><blockquote>
<p>Sequence locus are noted between <span class="math inline">&lt;</span> and <span class="math inline">&gt;</span> . In addition each sequence alleles/haplotypes is noted between brackets. For instance, a haploid sequence locus will be noted <span class="math inline"> &lt; [</span>GTCTA<span class="math inline">]&gt;</span> and a diploid sequence locus <span class="math inline"> &lt; [</span>GTCTA<span class="math inline">][</span>GTCTT<span class="math inline">]&gt;</span>. Sequences may contain undetermined nucleotides which will be denoted "N " or " - ". Note that all sequence alleles/haplotypes have to be of same length. The length of shorter sequence allele/haplotypes needs to be adjusted to the larger sequence allele/haplotype by adding "N " or " - " symbols at the end of the sequences. It is worth stressing that, at a given locus, only the portion of the sequence shared by all individuals of the dataset will be used for computing summary statistics. We therefore advise removing locus-individual sequence data with too many “N” and replace them by missing data. Finally, remember that this version of the program does not consider insertion-deletion mutations, mainly because there does not seem to be much consensus on this topic.</p>
</blockquote></li>
<li><blockquote>
<p>Missing microsatellite genotypes are noted 000 if haploid or 000000 if diploid.</p>
</blockquote></li>
<li><blockquote>
<p>Missing sequence alleles/haplotypes are noted <span class="math inline"> &lt; [ ]&gt;</span> if haploid or <span class="math inline"> &lt; [ ][ ]&gt;</span> if diploid.</p>
</blockquote></li>
<li><blockquote>
<p>Missing data are taken into account in the following way. For each appearance of a missing genotype in the observed dataset, the program records the individual and the locus. When simulating datasets, the program replaces the simulated genotype (obtained through the coalescence process algorithm) by the missing data code at all corresponding locations. All summary statistics are thus computed with the same missing data as for the observed dataset. <em>WARNING</em>: data files with virtually any amount of missing data can be analyzed by DIYABC Random Forest. <u>However, for each locus a minimum of one genotyped individual per population is required.</u> This is because summary statistics cannot be computed at a given locus in a given population if only missing data are present.</p>
</blockquote></li>
</ul>
<p><strong>EXAMPLES</strong></p>
<p><u>Example 1</u>: the example dataset below includes two population samples, each of 12 diploid individuals (8 females and 4 males in the first sample and 5 females and 7 males in the second sample). As deduced from the letter between <span class="math inline">&lt;</span> and <span class="math inline">&gt;</span> on the locus name lines (see page 25), these individuals have been genotyped at 3 microsatellite loci (1 autosomal <span class="math inline"> &lt; <em>A</em>&gt;</span>, 1 X-linked <span class="math inline"> &lt; <em>X</em>&gt;</span> and 1 Y-linked <span class="math inline"> &lt; <em>Y</em>&gt;</span>) and 3 DNA sequence loci (1 autosomal. 1 X-linked and 1 mitochondrial <span class="math inline"> &lt; <em>M</em>&gt;</span>). The species sex-ratio, given in the title line, is of three males for one female (<span class="math inline"> &lt; <em>N</em><em>M</em> = 3<em>N</em><em>F</em>&gt;</span>) or in other words, the number of males equals three times the number of females.</p>
<h1 id="image"><img src="media/image38.png" style="width:5.38333in;height:4.19167in" alt="image" /></h1>
<p><u>Example 2</u>: in this second example, the species is haploid. Individuals have been genotyped at three autosomal microsatellite loci and one mitochondrial DNA sequence locus. The species being haploid (deduced from the presence of autosomal haploid loci), no indication of the sex-ratio appears in the title line.</p>
<p><img src="media/image39.png" style="width:4.90625in;height:2.72917in" alt="image" /></p>
<h2 id="training-set-files">7.2 Training set file(s)</h2>
<p>Training set files are binary files which include two successive parts:</p>
<ul>
<li><p>The first file is a header (named <strong>headerRF.txt</strong>) which contains information necessary to read the second part (file), such as the number of scenarios, or the number of parameters of each scenario.</p></li>
<li><p>The second file (named <strong>reftableRF.bin</strong>) corresponds to the training set per se, as this file contains simulated dataset records, each record containing on the same line the scenario number, the parameter values and summary statistics values.</p></li>
</ul>
<p>Each time a training set (reftableRF.bin) is created or increased (each time the training set “Run” button is pressed), two text files are created in the project directory:</p>
<ul>
<li><p><strong>statobsRF.txt</strong>: this text file contains the values of summary statistics for the observed data set.</p></li>
<li><p><code>first_records_of_the_reference_table_X.txt</code> in which <code>X</code> is an integer number starting at 0 and increasing each time the training set “Run” button is pressed. This file provides a text version of the first <span class="math inline"><em>n</em></span> newly created records of the training set reftableRF.bin (<span class="math inline"><em>n</em></span> being equal to the <em>Particle loop size</em>, see section 3.7.3).</p></li>
</ul>
<h2 id="output-files-produced-by-a-random-forest-analysis">7.3 Output files produced by a Random Forest analysis</h2>
<p>DIYABC Random Forest provides various numerical and graphical outputs. The integration of the various graphical outputs is managed with the ggplot2 R package (Wickham 2016), allowing user to create and export high-quality graphics related to the analyses. Graphs are saved under the XXpngXX format and non-graphical outputs are saved in text files. Once a Random Forest analysis is terminated, do not forget to click on the “Save” button in the “Project housekeeping” panel to save a concatenated .zip file including the output files on your computer. The name of the concatenated .zip file is the one given at the start in the “Project name” window.</p>
<p>We now describe all the files produced by each Random Forest analysis.</p>
<p><u>Scenario choice analysis</u></p>
<ul>
<li><p><em>Numerical outputs</em></p></li>
</ul>
<p><strong>abcranger_mod_choice_call.log</strong>: log files with votes and posterior probability of the selected (i.e. best) scenario (i.e. model).</p>
<p><strong>modelchoice_out.confusion</strong>: mean misclassification error rate and confusion matrix (i.e. the contingency table of the true and predicted classes for each example in the training set). These indices are computed using the out-of-bag (a.k.a. out-of-bootstrap or OOB) training data as free test dataset.</p>
<p><strong>modelchoice_out.prediction</strong>: votes, prediction of the selected scenario and posterior probability of the selected scenario (i.e. model).</p>
<p><strong>modelchoice_out.ooberror</strong>: Evolution of prediction power relatively to the number of trees in the forest. Line number is the number of trees. Power is the global (prior) error rate for scenario choice with the mean taken as point estimate (computed using OOB). See the file modelchoice_out_graph_error_versus_ntrees.png for a graphical representation.</p>
<p><strong>modelchoice_out.importance</strong>: variables importance (sorted) which correspond to the contributions of the statistics to the Random Forest when choosing among scenarios. The variable importance of each statistics is computed as the mean decrease of impurity across the trees, where the impurity measure is the Gini index. Note that the scale is irrelevant: only the relative values matter. The variable importance was computed for each of the summary statistics provided by DIYABC Random Forest, plus the LDA axes (denoted LD) if they have been added to the feature vector. The higher the variable importance the more informative is the statistic. Variable importance of noise variables (denoted NOISEx and corresponding to values randomly drawn into uniform distributions bounded between 0 and 1) are also provided. Such noise variable can be added to the feature vector processed by RF in order to evaluate the threshold of variable importance values below which components of the vector are not informative anymore. More details about summary statistics including their code names can be found in section 2.6.3. Population index(s) are also indicated at the end of each statistics. See Collin et al. 2020 for examples. See the file modelchoice_out_graph_variable_importance.png for a graphical representation.</p>
<p><strong>modelchoice_out.lda:</strong> coordinates for the projection of the datasets from the training set and from the observed dataset on the first two linear discriminant analysis (LDA) axes when analyzing more than two scenarios (models) and on a single LDA axis when analyzing a pair of scenarios (or two groups of scenarios); See the file modelchoice_out_graph_lda.png for a graphical representation.</p>
<ul>
<li><p><em>Graphical outputs</em></p></li>
</ul>
<p><strong>modelchoice_out_graph_lda.png:</strong> Projection of the datasets from the training set on the first two linear discriminant analysis (LDA) axes when analyzing more than two scenarios (models) and on a single LDA axis when analyzing a pair of scenarios (or two groups of scenarios). The location of the observed dataset in the LDA projection is indicated by a star symbol or a vertical line. Graphical representation obtained from the text file modelchoice_out.lda; see also Figure 2 in Collin et al. 2020.</p>
<p><strong>modelchoice_out_graph_error_versus_ntrees.png:</strong> Evolution of prediction power relatively to the number of trees in the forest. Graphical representation obtained from the text file modelchoice_out.ooberror ; see also Figure S1 in Collin et al. 2020.</p>
<p><strong>modelchoice_out_graph_variable_importance.png:</strong> Contributions of the 50 most informative statistics (including LDA axes if computed) to the Random Forest when choosing among scenarios. Graphical representation obtained from the text file modelchoice_out.importance; see also Figure 3 in Collin et al. 2020.</p>
<p><u>Parameter estimation analysis</u></p>
<ul>
<li><p><em>Numerical outputs</em></p></li>
</ul>
<p><strong>abcranger_param_estim_call.log</strong>: this log files contains the main outputs of parameter estimation (including predictions and accuracy of estimation indices).</p>
<p><strong>estim_param_out.predictions</strong>: expectation, median, quantiles 0.05, quantile 0.95, and variance for prediction of parameter estimation</p>
<p><strong>estim_param_out.ooberror</strong>: Evolution of prediction power relatively to the number of trees in the forest. Line number is the number of trees. Power is the global (prior) mean squared error with the mean taken as point estimate (computed using OOB). See the file estim_param_out_graph_error_versus_ntrees.png for a graphical representation.</p>
<p><strong>estim_param_out.oobstats</strong>: this file contains various accuracy indices of parameter estimation (computed using OOB). Both global (prior) error indices and Local (posterior) error indices are provided (see Collin et al. 2020 for details).</p>
<p><strong>estim_param_out.importance</strong>: variables importance (sorted) which correspond to the contributions of the statistics to the Random Forest when processing parameter estimation. The variable importance of each statistics is computed as the mean decrease of impurity across the trees, where the impurity measure is the residual sum of squares. Note that the scale is irrelevant: only the relative values matter. The variable importance was computed for each of the summary statistics provided by DIYABC Random Forest, plus the PLS axes (denoted Comp.) if they have been added to the feature vector. The higher the variable importance the more informative is the statistic. Variable importance of noise variables (denoted NOISEx and corresponding to values randomly drawn into uniform distributions bounded between 0 and 1) are also provided. Such noise variable can be added to the feature vector processed by RF in order to evaluate the threshold of variable importance values below which components of the vector are not informative anymore. More details about summary statistics including their code names can be found in section 2.6.3. Population index(s) are also indicated at the end of each statistics. See Collin et al. 2020 for examples. See the file estim_param_out_graph_variable_importance.png for a graphical representation.</p>
<p><strong>estim_param_out.predweights</strong>: pairs of parameter value - weight value inferred during prediction. Such pairwise values can be used to do density plot of parameter estimation. See the file estim_param_out_graph_density_plot.png for a graphical representation.</p>
<p><em>If a Partial Least Squares Regression analysis (PLS) is processed on the summary statistics then two additional output files are provided.</em></p>
<p><strong>estim_param_out.plsvar</strong>: variance explained by number of the <em>c</em> selected PLS components (from component 1 to <em>c,</em> with c the number of PLS axes providing a given fraction of the maximum amount of variance explained by all PLS axes - 95% by default-).</p>
<p><strong>estim_param_out.plsweights</strong>: weight of each variable (i.e. summary statistics) for the first PLS component (sorted by absolute value)</p>
<ul>
<li><p><em>Graphical outputs</em></p></li>
</ul>
<p><strong>estim_param_out_graph_density_plot.png</strong>: density plot graphical representation for the estimated parameter (obtained from the text file estim_param_out.predweights).</p>
<p><strong>estim_param_out_graph_error_versus_ntrees.png:</strong> Evolution of prediction power relatively to the number of trees in the forest. Graphical representation obtained from the text file estim_param_out.ooberror; see also Figure S1 in Collin et al. 2020.</p>
<p><strong>estim_param_out_graph_variable_importance.png</strong>: Contributions of the 50 most informative statistics (including PLS axes if computed) to the Random Forest when choosing among scenarios. Graphical representation obtained from the text file estim_param_out.ooberror; see also Figure 3 in Collin et al. 2020.</p>
<h2 id="other-files">7.4 Other files</h2>
<p>The program writes several additional files in the saved project directory:</p>
<div class="Definition-Term">
<p>diyabcGUI_proj.txt: this file contain the project name</p>
</div>
<div class="Definition-Term">
<p>diyabc_run_call.log: this text file contains information about the first steps of the training set production, including the reading of the observed data file and the interpretation of the headerRF.txt file.</p>
</div>
<dl>
<dt>reftable.log: this file contains information about the progress of computations (achieved number of records)</dt>
<dd><p><strong>reftable.csv</strong>: this is a csv format of the file first_records_of_the_reference_table_X.txt file (see section 7.2)</p>
<p><strong>RNG_state_0000.bin</strong>: this binary file contains the current state of the random generator.</p>
<p><strong>diyabc_seed_init_call.log:</strong> this text file contains information about the initialization of the random generator</p>
</dd>
</dl>
<p><strong>8. USING DIYABC RANDOM FOREST ON A COMPUTER CLUSTER</strong></p>
<p>The computing effort is considerably reduced for ABC Random Forest, as the method requires a substantially smaller training set compared to ABC methods (e.g., a few thousands of simulated datasets versus hundreds of thousands of simulations per scenario for most ABC approaches; Blum &amp; François, 2010; Fraimout et al., 2017; Pudlo et al., 2016; Raynal et al., 2019). Given the ever-increasing dimensionality of modern genetic data generated using NGS technologies, this is a particularly appealing property of this method. Your personal computer or some small local server should hence represent sufficient computer resources to run most of your DIYABC Random Forest analyses in a descent time. However, in some cases (for instance when very large SNP datasets have to be simulated), it might be useful to take advantage of <u>a computer grid cluster, especially to generate the training set (i.e. the file reftableRF.bin)</u>.</p>
<p>To do this (i.e. generate the reftableRF.bin training set), load from the DIYABC Random Forest github site <a href="https://github.com/diyabc/diyabc">https://github.com/diyabc/diyabc</a> , the diyabc v3.0 binary (executable) file corresponding to your Operating System. You can also compile locally the diyabc v3.0 sources (also available at https://github.com/diyabc/diyabc) to obtain your own binary. Then run this binary by using command line instructions with parameters as detailed at https://github.com/diyabc/diyabc. Such command lines can be embedded in a bash script adapted to your cluster system.</p>
<p>The sources and various binary versions of the program abcranger, which corresponds to Random Forest inference engine part of the program DIYABC Random Forest, are also available at https://github.com/diyabc/diyabc. The program abcranger can also be run through command line instructions with parameters as detailed in https://github.com/diyabc/diyabc. Again, such command lines can be embedded in a bash script adapted to your cluster system. However, this is less crucial as Random Forest treatments with abcranger (using a given training set) are much more rapid than the generation of the training set with diyabc v3.0 (e.g. Collin et al. 2020).</p>
<p>It is worth stressing that abcranger is not limited to population genetics applications as the program can be used as a Random Forest inference engine independently from the diyabc simulator. However, for the moment, the binary standalone used by the DIYABC Random Forest interface handles only outputs produced by the diyabc simulator. A python wrapper (and example notebooks) is available at https://github.com/diyabc/abcranger and a R wrapper will be soon provided at the same site.</p>
<p><strong>9. REFERENCES CITED</strong></p>
<p>Beaumont, M., 2010. Approximate Bayesian computation in evolution and ecology. Annual Review of Ecology, Evolution, and Systematics, 41, 379–406.</p>
<p>Breiman, L., 2001. Random forests. Machine Learning, 45(1), 5–32.</p>
<p>Blum, M.G.B., &amp; François, O. , 2010.Non-linear regression models for Approximate Bayesian Computation. Statistics and computing. 20(1):63–73. https://doi.10.1007/s11222-009-9116-0</p>
<p>Chang, W., Cheng, J., Allaire, JJ, Xie, Y., &amp; McPherson J. ,2019. Shiny: Web Application Framework for R. R package version 1.4.0. https://CRAN.R-project.org/package=shiny</p>
<p>Chapuis, M-P R., Raynal, L., Plantamp, C., Meynard, CN., Blondin, L., Marin, J-M ., &amp; Estoup, A. , 2020. A young age of subspecific divergence in the desert locust Schistocerca gregaria, inferred by ABC Random Forest, bioRxiv, 671867, ver. 4 peer-reviewed by Peer Community in Evolutionary Biology. https://www.biorxiv.org/content/10.1101/671867v4</p>
<p>Choisy, M., P. Franck and J.M. Cornuet, 2004. Estimating admixture proportions with microsatellites: comparison of methods based on simulated data. <em>Mol. Ecol.</em> 13, 955-968.</p>
<p>Chakraborty R and L Jin, 1993. A unified approach to study hypervariable polymorphisms: statistical considerations of determining relatedness and population distances. EXS. <em>67</em>, 153?175.</p>
<p>Collin F-D, Raynal L, Durif G, Gautier M, Vitalis R, Marin J-M, Estoup A., 2020. DIYABC Random Forest v1.0: extending approximate Bayesian computation with supervised machine learning to infer demographic history from genetic polymorphisms. Submitted to Molecular Ecology Resources. ### bioRxiv ####</p>
<p>Cornuet J.M., V. Ravigné and A. Estoup, 2010. Inference on population history and model checking using DNA sequence and microsatellite data with the sofware DIYABC (v1.0). <em>BMC Bioinformatics</em> 11,401.</p>
<p>Cornuet J.M., F. Santos, M.A. Beaumont, C.P. Robert, J.M. Marin, D.J. Balding, T. Guillemaud and A. Estoup, 2008. Infering population history with DIYABC: a user-friendly approach to Approximate Bayesian Computations. <em>Bioinformatics</em>, 24 (23), 2713-2719.</p>
<p>Cornuet, J-M., Pudlo, P., Veyssier, J., Dehne-Garcia A., Gautier M., Leblois R., Marin J-M, and A. Estoup, 2014. DIYABC v2.0: a software to make approximate Bayesian computation inferences about population history using single nucleotide polymorphism, DNA sequence and microsatellite data. <em>Bioinformatics</em>. Vol. 30, no. 8, p11871189, doi: 10.1093/bioinformatics/btt763.</p>
<p>Jarne and J.M. Cornuet, 2002. Homoplasy and mutation model at microsatellite loci and their consequences for population genetics analysis. <em>Mol. Ecol.</em>, 11, 1591-1604.</p>
<p>Estoup, A., Raynal, L., Verdu, P., &amp; Marin, J-M. (2018) Model choice using Approximate Bayesian Computation and Random Forests: analyzes based on model grouping to make inferences about the genetic history of Pygmy human populations. Journal de la Société Française de Statistiques, 159(3), 167-190.</p>
<p>Excoffier, L., A. Estoup and J.M. Cornuet, 2005. Bayesian analysis of an admixture model with mutations and arbitrarily linked markers. <em>Genetics</em> 169, 1727-1738.</p>
<p>Fraimout, A., Debat, V., Fellous, S., Hufbauer, R. A., Foucaud, J., Pudlo, P.,…Estoup A. , 2017. Deciphering the routes of invasion of Drosophila suzukii by means of ABC Random Forest. Molecular biology and evolution, 34(4), 980–996. https:// doi.10.1093/molbev/msx050</p>
<p>Garza JC and E Williamson, 2001. Detection of reduction in population size using data from microsatellite DNA. <em>Mol. Ecol.</em> 10,305-318.</p>
<p>Gautier, M., Foucaud, J., Gharbi, K., Cezard, T., Galan, M., Loiseau, A., …, Estoup, A. , 2013. .Estimation of population allele frequencies from next-generation sequencing data: pool-versus individual-based genotyping. Molecular Ecology, 22(14), 3766-3779. http://doi.10.1111/mec.12360</p>
<p>Goldstein DB, Linares AR, Cavalli-Sforza LL, and Feldman MW, 1995. An evaluation of genetic distances</p>
<p>Hasegawa, M., Kishino, H and Yano, T., 1985. Dating the human-ape splitting by a molecular clock of mitochondrial DNA. <em>Journal of Molecular Evolution</em> 22:160-174.</p>
<p>Hivert, V., Leblois, R., Petit, E. J., Gautier, M., &amp; Vitalis, R , 2018. Measuring genetic differentiation from pool-seq data. Genetics, 210(1): 31-330. https://doi.10.1534/genetics.118.300900</p>
<p>Hudson,R., M. Slatkin and W.P. Maddison, 1992. Estimation of levels of gene flow fom DNA sequence data. <em>Genetics</em>, 132, 583-589.</p>
<p>Hudson, R., 2002. Generating samples under a Wright-Fisher neutral model of genetic variation. <em>Bioinformatics</em>, 18: 337-338.</p>
<p>Jukes, TH and Cantor, CR., 1969. Evolution of protein molecules. Pp. 21-123 in H. N. Munro, ed. <em>Mammalian protein metabolism</em>. Academic Press, New York.</p>
<p>Kimura, M., 1980. A simple method for estimating evolutionary rate of base substitution through comparative studies of nucleotide sequences. <em>Journal of Molecular Evolution</em> 16:111-120.</p>
<p>Leblois R., Gautier M., Rohfritsch A., Foucaud J., Burban C., Galan M.,…,Kerdelhué C. ,2018. Deciphering the demographic history of allochronic differentiation in the pine processionary moth Thaumetopoea pityocampa. Molecular Ecology, 27(1), 264-278. doi.10.1111/mec.14411</p>
<p>Meinshausen, N. , 2006. Quantile regression forests. Journal of Machine Learning Research, 7, 983–999. https://dl.acm.org/doi/10.5555/1248547.1248582</p>
<p>Nei M., 1972. Genetic distance between populations. <em>Am. Nat.</em> 106:283-292</p>
<p>Nei M., 1987. <em>Molecular Evolutionary Genetics</em>. Columbia University Press, New York, 512 pp.</p>
<p>Patterson, N., Moorjani, P., Luo, Y., Mallick, S., Rohland, N., Zhan, Y., &amp; Reich, D. , 2012. Ancient admixture in human history. Genetics, 192 ,3), 1065–1093. https://doi.org/10.1534/genetics.112.145037</p>
<p>Pascual, M., M.P. Chapuis, F. Mestres, J. Balanyá, R.B. Huey, G.W. Gilchrist, L. Serra and A. Estoup, 2007. Introduction history of <em>Drosophila subobscura</em> in the New World: a microsatellite based survey using ABC methods. <em>Mol. Ecol.</em>, 16, 3069-3083.</p>
<p>Pollock DD, Bergman A, Feldman MW, Goldstein DB, 1998. Microsatellite behavior with range constraints: parameter estimation and improved distances for use in phylogenetic reconstruction. <em>Theoretical Population Biology</em>, 53, 256?271.</p>
<p>Pudlo, P., Marin, J.-M., Estoup, A., Cornuet, J.-M., Gautier, M., &amp; Robert, C. P. , 2016. Reliable ABC model choice via random forests. Bioinformatics, 32(6), 859–866. https://doi.10.1093/bioinformatics/btv684</p>
<p>Rannala, B., and J. L. Mountain, 1997. Detecting immigration by using multilocus genotypes. <em>Pro. Nat. Acad. Sci. USA</em> 94, 9197-9201.</p>
<p>Raymond M., and F. Rousset, 1995. Genepop (version 1.2), population genetics software for exact tests and ecumenicism. <em>J. Hered.</em>, 86, 248-249</p>
<p>Raynal L., Marin J-M., Pudlo P., Ribatet M., Robert C.P., &amp; Estoup A , 2019. ABC random forests for Bayesian parameter inference. Bioinformatics, 35(10), 1720–1728. https://doi.10.1093/bioinformatics/bty867</p>
<p>Schlötterer, C., Tobler, R., Kofler, R., &amp; Nolte, V. , 2014. Sequencing pools of individuals - mining genome-wide polymorphism data without big funding. Nature Reviews Genetics, 15(11), 749-763. doi.10.1038/nrg3803</p>
<p>Schrider, D.R., &amp; Kern, A.D. , 2018. Supervised machine learning for population genetics: a new paradigm. Trends in Genetics, 34(4), 301-312. https://doi.org/10.1016/j.tig.2017.12.005</p>
<p>Tajima, F., 1989. Statistical method for testing the neutral mutationhypothesis by DNA polymorphism. <em>Genetics</em> 123: 585-595</p>
<p>Tamura, K., and M. Nei., 1993. Estimation of the number of nucleotide substitutions in the control region of mitochondrial DNA in humans and chimpanzees. <em>Molecular Biology and Evolution</em> 10:512-526.</p>
<p>Weir BS and CC Cockerham , 1984. Estimating F-statistics for the analysis of population structure. <em>Evolution</em> 38: 1358-1370.</p>
<p>Weir, BS., &amp; Goudet, J. , 2017. A unified characterization of population structure and relatedness. Genetics, 206(4), 2085-2103. https://doi.10.1534/genetics.116.198424</p>
<p>Wickham, H. (2016) ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. ISBN 978-0-387-98141-3</p>
